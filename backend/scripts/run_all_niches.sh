#!/bin/bash
# TÃ¼m niche'leri sÄ±rayla Ã§alÄ±ÅŸtÄ±r â€” hedef: her niche'ten min 100 viral tweet
# Dual cookie rotation aktif, 15dk rate limit arasÄ±

set -e
cd /opt/contentfactory/backend
source venv/bin/activate
export $(grep -v '^#' .env | xargs)

LOG_DIR="/tmp/viral_collect"
mkdir -p "$LOG_DIR"

echo "$(date) - Viral Tweet Collection v3 (hedef: 100+/niche)"
echo "============================================="

# Haber: tekrar tara, daha derin (10 sayfa) + daha dÃ¼ÅŸÃ¼k eÅŸik (20 like)
echo ""
echo "$(date) - ğŸš€ haber niche'i (derin tarama, min 20 like)..."
python3 -u scripts/collect_viral_tweets.py \
    --niche haber --min-likes 1000 --max-pages 10 \
    2>&1 | tee "$LOG_DIR/haber_deep.log"
echo "$(date) - âœ… haber tamamlandÄ±"
echo "$(date) - â³ 15dk bekleniyor..."
sleep 900

# Kripto
echo ""
echo "$(date) - ğŸš€ kripto niche'i..."
python3 -u scripts/collect_viral_tweets.py \
    --niche kripto --min-likes 1000 --max-pages 10 \
    2>&1 | tee "$LOG_DIR/kripto.log"
echo "$(date) - âœ… kripto tamamlandÄ±"
echo "$(date) - â³ 15dk bekleniyor..."
sleep 900

# Mizah
echo ""
echo "$(date) - ğŸš€ mizah niche'i..."
python3 -u scripts/collect_viral_tweets.py \
    --niche mizah --min-likes 1000 --max-pages 10 \
    2>&1 | tee "$LOG_DIR/mizah.log"
echo "$(date) - âœ… mizah tamamlandÄ±"
echo "$(date) - â³ 15dk bekleniyor..."
sleep 900

# Ä°Ã§erik Ã¼retici
echo ""
echo "$(date) - ğŸš€ icerik_uretici niche'i..."
python3 -u scripts/collect_viral_tweets.py \
    --niche icerik_uretici --min-likes 1000 --max-pages 10 \
    2>&1 | tee "$LOG_DIR/icerik_uretici.log"
echo "$(date) - âœ… icerik_uretici tamamlandÄ±"
echo "$(date) - â³ 15dk bekleniyor..."
sleep 900

# Finans
echo ""
echo "$(date) - ğŸš€ finans niche'i..."
python3 -u scripts/collect_viral_tweets.py \
    --niche finans --min-likes 1000 --max-pages 10 \
    2>&1 | tee "$LOG_DIR/finans.log"
echo "$(date) - âœ… finans tamamlandÄ±"
echo "$(date) - â³ 15dk bekleniyor..."
sleep 900

# Tech: tekrar tara (yeni tweet'ler + pagination ile daha derin)
echo ""
echo "$(date) - ğŸš€ tech niche'i (derin tekrar tarama)..."
python3 -u scripts/collect_viral_tweets.py \
    --niche tech --min-likes 1000 --max-pages 10 \
    2>&1 | tee "$LOG_DIR/tech_deep.log"
echo "$(date) - âœ… tech tamamlandÄ±"
echo "$(date) - â³ 15dk bekleniyor..."
sleep 900

# Pazarlama: tekrar tara (daha derin)
echo ""
echo "$(date) - ğŸš€ pazarlama niche'i (derin tekrar tarama)..."
python3 -u scripts/collect_viral_tweets.py \
    --niche pazarlama --min-likes 1000 --max-pages 10 \
    2>&1 | tee "$LOG_DIR/pazarlama_deep.log"
echo "$(date) - âœ… pazarlama tamamlandÄ±"
echo "$(date) - â³ 15dk bekleniyor..."
sleep 900

# KiÅŸisel geliÅŸim: tekrar tara
echo ""
echo "$(date) - ğŸš€ kisisel_gelisim niche'i (derin tekrar tarama)..."
python3 -u scripts/collect_viral_tweets.py \
    --niche kisisel_gelisim --min-likes 1000 --max-pages 10 \
    2>&1 | tee "$LOG_DIR/kisisel_gelisim_deep.log"
echo "$(date) - âœ… kisisel_gelisim tamamlandÄ±"

echo ""
echo "$(date) - ğŸ‰ TÃœM NÄ°CHE'LER TAMAMLANDI"
echo "============================================="

# Supabase'den niche bazlÄ± sayÄ±lar
python3 -c "
import httpx, os
url = os.environ['SUPABASE_URL'] + '/rest/v1/viral_tweets'
key = os.environ['SUPABASE_SERVICE_KEY']
headers = {'apikey': key, 'Authorization': 'Bearer ' + key}
r = httpx.get(url + '?select=niche', params={'limit': 50000}, headers=headers)
data = r.json()
by_niche = {}
for d in data:
    n = d.get('niche', '?')
    by_niche[n] = by_niche.get(n, 0) + 1
print(f'\nToplam: {len(data)} viral tweet')
for n, c in sorted(by_niche.items(), key=lambda x: -x[1]):
    status = 'âœ…' if c >= 100 else 'âš ï¸'
    print(f'  {status} {n}: {c}')
"
