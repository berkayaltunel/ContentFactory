# ContentFactory - Prompt Builder v3
# 5-section architecture: GÃ–REV â†’ SES â†’ KURALLAR â†’ Ã–RNEKLER â†’ SON KONTROL
# Designed for single-pass quality over constraint overload

from .personas import PERSONAS
from .tones import TONES
from .knowledge import KNOWLEDGE_MODES
from .quality import LENGTH_CONSTRAINTS, REPLY_MODES, ARTICLE_STYLES, APEX_MODE

from .linkedin import LINKEDIN_SYSTEM_PROMPT
from .instagram import INSTAGRAM_SYSTEM_PROMPT
from .blog import BLOG_SYSTEM_PROMPT
from .youtube import YOUTUBE_SYSTEM_PROMPT
from .tiktok import TIKTOK_SYSTEM_PROMPT

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SECTION 1: GÃ–REV (Task)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_TASK_TEMPLATES = {
    "tweet": "Verilen konuya gÃ¶re tweet yaz. Scroll durdurucu aÃ§Ä±lÄ±ÅŸ, net mesaj, deÄŸer katan iÃ§erik.",
    "quote": "AÅŸaÄŸÄ±daki tweet'e quote tweet yaz. BoÅŸ Ã¶vgÃ¼ yasak â€” kendi perspektifini ekle, deÄŸer kat.\n\nOrijinal tweet:\n{original_tweet}",
    "reply": "AÅŸaÄŸÄ±daki tweet'e reply yaz. BaÄŸlama uygun, deÄŸer katan, doÄŸal bir yanÄ±t.\n\nReply atacaÄŸÄ±n tweet:\n{original_tweet}",
    "article": "X/Twitter Article formatÄ±nda uzun form iÃ§erik yaz. GÃ¼Ã§lÃ¼ baÅŸlÄ±k, hooklu giriÅŸ, bÃ¶lÃ¼mlenmiÅŸ yapÄ±, takeaway'li kapanÄ±ÅŸ.",
    "linkedin": "LinkedIn iÃ§in profesyonel iÃ§erik yaz. Ä°lk 2-3 satÄ±r hook, kÄ±sa paragraflar, net insight.",
    "instagram": "Instagram iÃ§in caption yaz. Hook ile baÅŸla, kÄ±sa paragraflar, engagement odaklÄ±.",
    "blog": "Blog yazÄ±sÄ± yaz. SEO uyumlu yapÄ±, Ã¶rneklerle desteklenmiÅŸ, actionable sonuÃ§.",
    "youtube": "YouTube iÃ§in iÃ§erik yaz. CTR optimize baÅŸlÄ±k, retention odaklÄ± yapÄ±.",
    "tiktok": "TikTok iÃ§in kÄ±sa form video scripti yaz. Ä°lk 1-3 saniye hook, hÄ±zlÄ± tempo, loop-friendly.",
}


_DIRECTION_RULES = {
    "support": "âš ï¸ YÃ–N: Bu tweet'e KATIL ve DESTEKLE. ÃœstÃ¼ne koy, gÃ¼Ã§lendir, ek perspektif sun. KarÅŸÄ± Ã§Ä±kma.",
    "oppose": "âš ï¸ YÃ–N: Bu tweet'e KARÅžI Ã‡IK. ZÄ±t gÃ¶rÃ¼ÅŸ belirt, argÃ¼manÄ± Ã§Ã¼rÃ¼t veya sorgula. Ama saygÄ±lÄ± kal, trolleme.",
    "add": "âš ï¸ YÃ–N: Bu tweet'in ÃœSTÃœNE BÄ°LGÄ° EKLE. Yeni bir perspektif, veri, Ã¶rnek veya baÄŸlam sun. Tekrar etme, deÄŸer kat.",
    "roast": "âš ï¸ YÃ–N: Bu tweet'le DALGA GEÃ‡. Ä°ronik, komik, zekice yaklaÅŸ. KÄ±rÄ±cÄ± deÄŸil eÄŸlenceli ol. Shitpost energy.",
}


def _build_gorev(content_type: str, topic: str = None, original_tweet: str = None,
                 reply_mode: str = None, article_style: str = None,
                 references: list = None, additional_context: str = None,
                 direction: str = None, direction_custom: str = None) -> str:
    """Section 1: GÃ–REV â€” ne Ã¼retilecek."""
    task = _TASK_TEMPLATES.get(content_type, _TASK_TEMPLATES["tweet"])
    if original_tweet and "{original_tweet}" in task:
        task = task.format(original_tweet=original_tweet)

    parts = [f"## GÃ–REV\n\n{task}"]

    # Direction (quote/reply yÃ¶nlendirme)
    if content_type in ("quote", "reply"):
        if direction_custom:
            parts.append(f"âš ï¸ YÃ–N (kullanÄ±cÄ± talimatÄ±): {direction_custom}")
        elif direction and direction in _DIRECTION_RULES:
            parts.append(_DIRECTION_RULES[direction])

    if reply_mode and reply_mode in REPLY_MODES:
        rm = REPLY_MODES[reply_mode]
        parts.append(f"Reply modu: {rm['name']} â€” {rm['approach']}")

    if article_style and article_style in ARTICLE_STYLES:
        ast = ARTICLE_STYLES[article_style]
        parts.append(f"Makale stili: {ast['name']} â€” {ast['structure']}")

    if references:
        parts.append("Referanslar:\n" + "\n".join(f"â€¢ {r}" for r in references))

    if additional_context:
        parts.append(f"Ek baÄŸlam: {additional_context}")

    if topic:
        parts.append(f"Konu: {topic}")

    return "\n\n".join(parts)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SECTION 2: SES (Voice = Style > Persona > Tone)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_PLATFORM_PROMPTS = {
    "linkedin": LINKEDIN_SYSTEM_PROMPT,
    "instagram": INSTAGRAM_SYSTEM_PROMPT,
    "blog": BLOG_SYSTEM_PROMPT,
    "youtube": YOUTUBE_SYSTEM_PROMPT,
    "tiktok": TIKTOK_SYSTEM_PROMPT,
}

def _extract_persona_essence(persona_id: str) -> str:
    """Persona'nÄ±n Ã¶zÃ¼nÃ¼ 3-5 cÃ¼mleye sÄ±kÄ±ÅŸtÄ±r."""
    if not persona_id:
        return ""
    p = PERSONAS.get(persona_id, PERSONAS.get("otorite"))
    if not p:
        return ""
    identity = p.get("identity", "").strip()
    voice = p.get("voice_characteristics", [])
    voice_str = ", ".join(voice[:3]) if voice else ""
    avoid = p.get("avoid", [])
    avoid_str = ", ".join(avoid[:3]) if avoid else ""

    lines = [f"Persona: {p['name']} â€” {p['description']}"]
    if identity:
        # Take first 2 sentences of identity
        sentences = [s.strip() for s in identity.replace("\n", " ").split(".") if s.strip()]
        lines.append(". ".join(sentences[:2]) + ".")
    if voice_str:
        lines.append(f"Ses: {voice_str}.")
    if avoid_str:
        lines.append(f"KaÃ§Ä±n: {avoid_str}.")
    return "\n".join(lines)


def _extract_tone_essence(tone_id: str) -> str:
    """Ton'un Ã¶zÃ¼nÃ¼ 2-3 cÃ¼mleye sÄ±kÄ±ÅŸtÄ±r."""
    t = TONES.get(tone_id, TONES.get("natural"))
    if not t:
        return ""
    core = t.get("core_principle", "").strip().replace("\n", " ")
    # Take first sentence of core principle
    sentences = [s.strip() for s in core.split(".") if s.strip()]
    first = ". ".join(sentences[:2]) + "." if sentences else ""

    dos = t.get("dos_and_donts", {}).get("do", [])[:3]
    donts = t.get("dos_and_donts", {}).get("dont", [])[:3]

    lines = [f"Ton: {t['name']} â€” {t['description']}"]
    if first:
        lines.append(first)
    if dos:
        lines.append("Yap: " + ", ".join(dos) + ".")
    if donts:
        lines.append("Yapma: " + ", ".join(donts) + ".")
    return "\n".join(lines)



BASE_PROHIBITIONS = """
### KÄ±rÄ±lmaz Yasaklar
- AI kalÄ±plarÄ± YASAK: "UnutmayÄ±n ki", "SonuÃ§ olarak", "Ä°ÅŸte size", "Siz ne dÃ¼ÅŸÃ¼nÃ¼yorsunuz?"
- Emoji, hashtag, Ã¼Ã§ nokta (...), clickbait ("Ä°ÅŸin sÄ±rrÄ±...") YASAK
- Tespitini yap ve BIRAK. AÃ§Ä±klama, Ã¶zet, soru ile bitirme.
"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TONE VOICE GUIDES â€” Her ton iÃ§in "nasÄ±l yaz" kÄ±lavuzu
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TONE_VOICE_GUIDES = {
    "witty": {
        "label": "Esprili",
        "voice": "Keskin ironi, beklenmedik final, deadpan humor. Espriyi yap ve orada bÄ±rak, aÃ§Ä±klama. Okuyucu 2 saniye dÃ¼ÅŸÃ¼nsÃ¼n, sonra gÃ¼lsÃ¼n.",
        "hook": "Ä°ronik zÄ±tlÄ±k veya absÃ¼rt bir gÃ¶zlemle aÃ§. Herkesin bildiÄŸi bir ÅŸeyi ters Ã§evir.",
        "example_energy": "Twitter'daki 'Ã¶lÃ¼m' esprileri. Kuru, zeki, acÄ±masÄ±z.",
    },
    "aggressive": {
        "label": "Agresif",
        "voice": "Direkt, korkusuz, tartÄ±ÅŸma baÅŸlat. Hot take formatÄ±. Ã–zÃ¼r dileme, yumuÅŸatma, 'ama tabii herkesin fikri farklÄ± olabilir' ekleme.",
        "hook": "SarsÄ±cÄ± bir iddia veya meydan okumayla aÃ§. PopÃ¼ler bir gÃ¶rÃ¼ÅŸe direkt karÅŸÄ± Ã§Ä±k.",
        "example_energy": "TartÄ±ÅŸma baÅŸlatan, insanlarÄ±n RT yapÄ±p 'buna katÄ±lmÄ±yorum ama...' dediÄŸi tweetler.",
    },
    "informative": {
        "label": "Bilgi Verici",
        "voice": "Veriyle konuÅŸ, insight ver. 'Bunu bilmiyordunuz' hissi yarat. Otorite ol ama ukala olma.",
        "hook": "ÅžaÅŸÄ±rtÄ±cÄ± bir istatistik, az bilinen bir gerÃ§ek veya yaygÄ±n bir yanÄ±lgÄ±yÄ± yÄ±kan bir cÃ¼mleyle aÃ§.",
        "example_energy": "'TIL (Today I Learned)' hissi. Okuyucu kaydedip paylaÅŸmak istesin.",
    },
    "friendly": {
        "label": "Samimi",
        "voice": "1. tekil ÅŸahÄ±s, kiÅŸisel deneyim, arkadaÅŸÄ±na anlatÄ±yormuÅŸ gibi. Samimi ama yÃ¼zeysel deÄŸil.",
        "hook": "KiÅŸisel bir anekdot veya 'dÃ¼n baÅŸÄ±ma ÅŸu geldi' formatÄ±yla aÃ§. Okuyucu kendini bulsun.",
        "example_energy": "Kahve sohbetindeki o zeki arkadaÅŸ. Rahat ama derin.",
    },
    "inspirational": {
        "label": "Ä°lham Verici",
        "voice": "Vizyon Ã§iz, bÃ¼yÃ¼k dÃ¼ÅŸÃ¼n. Motivasyonel kliÅŸeler YASAK. GerÃ§ek deneyimden gelen bilgelik.",
        "hook": "'Ya ÅŸÃ¶yle olsaydÄ±' veya geleceÄŸe dair cesur bir Ã¶ngÃ¶rÃ¼yle aÃ§.",
        "example_energy": "Steve Jobs keynote'u, motivasyonel poster deÄŸil. BÃ¼yÃ¼k resmi gÃ¶r, kÃ¼Ã§Ã¼k adÄ±mÄ± sÃ¶yle.",
    },
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONTENT ARCHITECTURE â€” Twitter UstalÄ±ÄŸÄ± KurallarÄ±
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CONTENT_ARCHITECTURE = """
### Ä°Ã§erik Mimarisi

**RÄ°TÄ°M:** Setup â†’ satÄ±r boÅŸluÄŸu â†’ Punchline. Blok metin yazma, nefes ver.
**SENTEZ:** Birden fazla ton varsa TEK ruh hali yarat (agresif+esprili = sarcastic). Bipolar olma.
**SHOW DON'T TELL:** Tespitini yap ve BIRAK. "Yani kÄ±sacasÄ±" diye aÃ§Ä±klama.
**KUSURLULUK:** KÃ¼Ã§Ã¼k harfle baÅŸla, bazen nokta koyma. Organik hissettir.
"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FEW-SHOT EXAMPLES â€” Her ton iÃ§in viral tweet Ã¶rnekleri
# AI kuraldan Ã§ok Ã¶rnekten Ã¶ÄŸrenir. BunlarÄ± kopyalama ama ritimlerini taklit et.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

FEW_SHOT_EXAMPLES = {
    "witty": [
        "herkes yapay zekadan iÅŸ kaybetmekten korkuyor\n\nkardeÅŸim sen zaten 4 saat Excel'e bakÄ±p 2 satÄ±r yazÄ±yorsun, yapay zeka seni deÄŸil sen yapay zekayÄ± kurtarÄ±rsÄ±n",
        "startup kurucularÄ± \"baÅŸarÄ±sÄ±zlÄ±k Ã¶ÄŸreticidir\" diyor\n\nÃ¶ÄŸretici olan senin 3. pivot'un deÄŸil, yatÄ±rÄ±mcÄ±nÄ±n yÃ¼z ifadesi",
        "linkedinde \"open to work\" yazanlarÄ±n %90'Ä± aslÄ±nda open to compliment",
    ],
    "aggressive": [
        "herkes AI wrapper yapÄ±p \"SaaS kurdum\" diyor\n\nbir API key'i .env'e yazmak seni founder yapmÄ±yor",
        "\"network'Ã¼n net worth'Ã¼ndÃ¼r\" diyen adamÄ±n network'Ã¼ 3 tane LinkedIn motivasyon hesabÄ±",
        "Turkish startup ekosistemi: aynÄ± 50 kiÅŸi birbirinin eventine gidip \"ekosistem bÃ¼yÃ¼yor\" diyor",
    ],
    "informative": [
        "OpenAI'Ä±n yÄ±llÄ±k geliri 2 milyar dolarÄ± geÃ§ti ama hala kar etmiyor\n\nbu detayÄ± atlayan herkes 2000'lerin dotcom balonunu da atlamÄ±ÅŸ demektir",
        "RAG sistemlerinde chunk size 512 token Ã¼stÃ¼ne Ã§Ä±kÄ±nca retrieval kalitesi %40 dÃ¼ÅŸÃ¼yor\n\nkoca dokÃ¼manÄ± olduÄŸu gibi embedding'e atÄ±p \"Ã§alÄ±ÅŸmÄ±yor\" diyenler burada mÄ±",
        "TÃ¼rkiye'de SaaS churn rate ortalamasÄ± %8-12\n\nABD'de bu %5. Fark onboarding'de, Ã¼rÃ¼nde deÄŸil",
    ],
    "friendly": [
        "geÃ§en hafta mÃ¼ÅŸteriyle toplantÄ±daydÄ±m, adam \"biz aslÄ±nda ne istediÄŸimizi bilmiyoruz\" dedi\n\nen dÃ¼rÃ¼st brief buydu. keÅŸke herkes bÃ¶yle baÅŸlasa",
        "junior developer'ken her PR'da kalp krizi geÃ§irirdim\n\nÅŸimdi senior'Ä±m, hala geÃ§iriyorum ama artÄ±k bunu normalize ettim",
        "bir projede en Ã§ok zaman alan ÅŸey kod yazmak deÄŸil\n\nherkesin \"bence ÅŸÃ¶yle olmalÄ±\"sÄ±nÄ± dinleyip ortak bir \"tamam ÅŸÃ¶yle yapalÄ±m\"a ulaÅŸmak",
    ],
    "inspirational": [
        "herkes product-market fit arÄ±yor\n\nasÄ±l zor olan founder-problem fit. senin gerÃ§ekten umursadÄ±ÄŸÄ±n bir problem mi bu, yoksa pazar bÃ¼yÃ¼k diye mi girdin",
        "10 yÄ±l Ã¶nce \"mobil first\" dediler herkes gÃ¼ldÃ¼\n\nÅŸimdi \"AI first\" diyenlere de gÃ¼lÃ¼yorlar. pattern aynÄ±, sadece gÃ¼lenlerin Ã¶mrÃ¼ kÄ±salÄ±yor",
        "en iyi kariyer hamlelerim hep \"mantÄ±ksÄ±z\" denen ÅŸeylerdi\n\nspreadsheet'ler gÃ¼venli hissettirir ama hayat spreadsheet'te yaÅŸanmÄ±yor",
    ],
}


def _build_brand_voice_section(brand_voice: dict = None) -> str:
    """Brand Voice DNA from Creator Hub profile. Background layer, overridden by persona/tone."""
    if not brand_voice:
        return BASE_PROHIBITIONS
    tones = brand_voice.get("tones", {})
    principles = brand_voice.get("principles", [])
    avoid = brand_voice.get("avoid", [])
    sample_voice = brand_voice.get("sample_voice", "")
    active_tones = {k: v for k, v in tones.items() if v > 0}
    if not active_tones and not principles and not avoid and not sample_voice:
        return ""
    parts = ["### Marka DNA (Arka Plan)"]
    parts.append("Bu kullanÄ±cÄ±nÄ±n genel yazÄ±m eÄŸilimidir. Persona ve Ton seÃ§imleri bunu override edebilir.")
    if active_tones:
        sorted_tones = sorted(active_tones.items(), key=lambda x: -x[1])
        dominant = sorted_tones[:2]
        minor = sorted_tones[2:]

        # Dominant tonlarÄ±n voice guide'larÄ±nÄ± ekle
        for key, val in dominant:
            guide = TONE_VOICE_GUIDES.get(key)
            if guide:
                parts.append(f"\n**ANA TON: %{val} {guide['label']}**")
                parts.append(f"Ses: {guide['voice']}")
                parts.append(f"Hook: {guide['hook']}")

        # Sentez ipucu (2+ dominant ton varsa)
        if len(dominant) >= 2:
            k1, v1 = dominant[0]
            k2, v2 = dominant[1]
            l1 = TONE_VOICE_GUIDES.get(k1, {}).get("label", k1)
            l2 = TONE_VOICE_GUIDES.get(k2, {}).get("label", k2)
            parts.append(f"\nSENTEZ: {l1} + {l2} tonlarÄ±nÄ± ayrÄ± cÃ¼mleler olarak deÄŸil, TEK bir ruh halinde birleÅŸtir.")

        if minor:
            min_parts = [f"%{v} {TONE_VOICE_GUIDES.get(k, {}).get('label', k)}" for k, v in minor if v >= 10]
            if min_parts:
                parts.append(f"Hafif dokunuÅŸ: {', '.join(min_parts)}")

    # Target Audience
    audience = brand_voice.get("target_audience")
    if audience:
        audience_guides = {
            "beginners": "HEDEF KÄ°TLE: Yeni baÅŸlayanlar. Basit dil, sÄ±fÄ±r jargon, aÃ§Ä±klayÄ±cÄ± ama patronluk taslama.",
            "professionals": "HEDEF KÄ°TLE: SektÃ¶r profesyonelleri. Mesleki derinlik, teknik terimler kullanabilirsin, 101 seviyesi deÄŸil.",
            "clevel": "HEDEF KÄ°TLE: C-Level yÃ¶neticiler. Stratejik ve vizyoner dil, ROI/impact odaklÄ±, kÄ±sa ve Ã¶zlÃ¼.",
            "founders": "HEDEF KÄ°TLE: GiriÅŸimciler ve yatÄ±rÄ±mcÄ±lar. BÃ¼yÃ¼me metrikleri, pazar dinamikleri, cesur Ã¶ngÃ¶rÃ¼ler.",
        }
        guide = audience_guides.get(audience)
        if guide:
            parts.append(f"\n{guide}")

    # Content Architecture (her zaman)
    parts.append(CONTENT_ARCHITECTURE)
    # Pre-defined chip key â†’ label mapping
    principle_labels = {
        "concise": "KÄ±sa ve Ã–z", "data-driven": "Veri OdaklÄ±", "question-hook": "Soru ile BaÅŸla",
        "storytelling": "HikayeleÅŸtirici", "actionable": "Uygulanabilir Tavsiye", "personal": "KiÅŸisel Deneyim",
        "contrarian": "KarÅŸÄ±t GÃ¶rÃ¼ÅŸ", "educational": "Ã–ÄŸretici", "thread-style": "Thread FormatÄ±", "visual-first": "GÃ¶rsel AÄŸÄ±rlÄ±klÄ±",
    }
    avoid_labels = {
        "emoji-spam": "Emoji Spam", "clickbait": "TÄ±klama TuzaÄŸÄ±", "corporate": "Kurumsal Dil",
        "slang": "AÅŸÄ±rÄ± Argo", "generic": "Genel GeÃ§er KliÅŸe", "self-promo": "SÃ¼rekli Reklam",
        "negativity": "Negatif Ton", "jargon": "Teknik Jargon", "long-winded": "Gereksiz Uzun", "hashtag-spam": "Hashtag Spam",
    }
    if principles:
        p_labels = [principle_labels.get(p, p) for p in principles[:5]]
        parts.append(f"Ä°LKELER: {', '.join(p_labels)}")
    if avoid:
        a_labels = [avoid_labels.get(a, a) for a in avoid[:5]]
        parts.append(f"YASAKLAR: {', '.join(a_labels)}")

    # Few-shot Ã¶rnekler (dominant tonlara gÃ¶re)
    if active_tones:
        sorted_for_examples = sorted(active_tones.items(), key=lambda x: -x[1])
        examples = []
        for key, _ in sorted_for_examples[:2]:
            examples.extend(FEW_SHOT_EXAMPLES.get(key, []))
        if examples:
            parts.append("\nÃ–RNEK TWEETLER (bu ritimde yaz, kopyalama):")
            for i, ex in enumerate(examples[:3], 1):
                parts.append(f"  {i}. {ex}")

    parts.append(BASE_PROHIBITIONS)
    return chr(10).join(parts)


def _build_ses(persona: str, tone: str, style_prompt: str = None,
               platform: str = "twitter", content_type: str = "tweet",
               brand_voice: dict = None) -> str:
    """Section 2: SES â€” nasÄ±l seslenecek. Ã–ncelik: stil > persona > ton."""
    parts = ["## SES\n"]

    # Platform-specific voice (non-Twitter platforms have their own system prompts)
    platform_key = content_type if content_type in _PLATFORM_PROMPTS else platform
    if platform_key in _PLATFORM_PROMPTS:
        # Extract first meaningful paragraph from platform prompt
        prompt = _PLATFORM_PROMPTS[platform_key]
        # Take first 500 chars as platform voice essence
        lines = [l.strip() for l in prompt.strip().split("\n") if l.strip() and not l.startswith("#")]
        platform_essence = "\n".join(lines[:8])
        if platform_essence:
            parts.append(f"### Platform Sesi\n{platform_essence}")

    # Style DNA (highest priority)
    if style_prompt:
        parts.append(f"### Stil DNA (EN YÃœKSEK Ã–NCELÄ°K)\n{style_prompt}\n\nBu kiÅŸinin aÄŸzÄ±ndan Ã§Ä±kmÄ±ÅŸ gibi yaz. Kelime seÃ§imi, cÃ¼mle yapÄ±sÄ±, ritim hep bu stilde. Ã‡akÄ±ÅŸma olursa stil kazanÄ±r.")

    # Persona essence
    persona_text = _extract_persona_essence(persona)
    if persona_text:
        parts.append(f"### Karakter\n{persona_text}")

    # Tone essence
    tone_text = _extract_tone_essence(tone)
    if tone_text:
        parts.append(f"### Ton\n{tone_text}")

    # Brand Voice DNA (background layer)
    bv_section = _build_brand_voice_section(brand_voice)
    if bv_section:
        parts.append(bv_section)

    # Twitter-specific base voice (only if no platform prompt)
    if platform == "twitter" and content_type in ("tweet", "quote", "reply", "article"):
        if platform_key not in _PLATFORM_PROMPTS:
            parts.append("GerÃ§ek bir Twitter kullanÄ±cÄ±sÄ± gibi yaz. KÄ±sa cÃ¼mleler, spesifik ol, emoji kullanma.")

    return "\n\n".join(parts)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SECTION 3: KURALLAR (Rules)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _build_kurallar(content_type: str, length: str, language: str,
                    knowledge: str = None, platform: str = "twitter") -> str:
    """Section 3: KURALLAR â€” length + platform + language + knowledge, kÄ±sa maddeler."""
    rules = ["## KURALLAR\n"]

    # Length
    type_constraints = LENGTH_CONSTRAINTS.get(content_type, LENGTH_CONSTRAINTS.get("tweet", {}))
    length_data = type_constraints.get(length, list(type_constraints.values())[0] if type_constraints else None)
    if length_data:
        min_c, max_c = length_data["chars"]
        rules.append(f"- Uzunluk: {min_c}â€“{max_c} karakter ({length_data['label']}). Bu aralÄ±ÄŸÄ±n dÄ±ÅŸÄ±na Ã§Ä±kma.")

    # Language
    lang_map = {
        "auto": "- Dil: Konunun diline gÃ¶re TÃ¼rkÃ§e veya Ä°ngilizce.",
        "tr": "- Dil: Kesinlikle TÃ¼rkÃ§e yaz.",
        "en": "- Language: Write in English only.",
    }
    rules.append(lang_map.get(language, lang_map["auto"]))

    # Knowledge mode (condensed)
    if knowledge and knowledge in KNOWLEDGE_MODES:
        km = KNOWLEDGE_MODES[knowledge]
        rules.append(f"- Bilgi modu: {km['name']} â€” {km['description']}")

    # Content type specific
    if content_type == "thread":
        rules.append("- Thread formatÄ±: Her tweet numaralÄ± (1/, 2/, 3/), her biri baÄŸÄ±msÄ±z deÄŸer versin.")
    elif content_type in ("tweet", "quote", "reply"):
        rules.append("- Sadece iÃ§eriÄŸi yaz. AÃ§Ä±klama, 'Ä°ÅŸte tweet:' gibi giriÅŸler yasak.")
        rules.append("- Thread ise numaralandÄ±r (1/, 2/, 3/). Tek iÃ§erik ise dÃ¼z metin.")

    return "\n".join(rules)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SECTION 4: Ã–RNEKLER (Examples / Few-shot)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _build_ornekler(example_tweets: list = None) -> str:
    """Section 4: Ã–RNEKLER â€” few-shot RAG, varsa."""
    if not example_tweets:
        return ""

    tweets = example_tweets[:15]
    lines = ["## Ã–RNEKLER\n\nBu kiÅŸinin gerÃ§ek tweet'leri. Kopyalama, ama aynÄ± kiÅŸi yazmÄ±ÅŸ gibi hissettir.\n"]

    for i, tweet in enumerate(tweets, 1):
        content = tweet.get("content", "") if isinstance(tweet, dict) else str(tweet)
        if len(content) > 400:
            content = content[:397] + "..."

        # Engagement tag
        tag = ""
        if isinstance(tweet, dict):
            likes = tweet.get("likes", 0)
            rts = tweet.get("retweets", 0)
            if likes >= 100 or rts >= 20:
                tag = f" [ðŸ”¥ {likes}â™¡ {rts}RT]"

        lines.append(f"{i}. {content}{tag}")

    return "\n".join(lines)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SECTION 5: SON KONTROL (Final Checklist)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_BANNED_WORDS = [
    "devrim", "Ã§Ä±ÄŸÄ±r aÃ§an", "oyun deÄŸiÅŸtirici", "game changer",
    "hazÄ±r mÄ±sÄ±nÄ±z", "hazÄ±r mÄ±yÄ±z", "hazÄ±r olun",
    "yeni bir dÃ¶nem", "yeni bir Ã§aÄŸ", "yeni bir sayfa",
    "kapÄ±larÄ± aÃ§Ä±yor", "kapÄ±larÄ± aÃ§acak", "kapÄ±sÄ±nÄ± aÃ§Ä±yor",
    "sÄ±nÄ±rlarÄ± zorlayan", "sÄ±nÄ±rlarÄ± aÅŸan",
    "inovasyon", "transformasyon", "paradigma",
    "dÃ¼ÅŸÃ¼nmek lazÄ±m", "dÃ¼ÅŸÃ¼nmek gerek",
    "hadi bakalÄ±m", "bir dÃ¼ÅŸÃ¼nÃ¼n", "merak etmeyin",
    "siz ne dÃ¼ÅŸÃ¼nÃ¼yorsunuz",
    "muhteÅŸem", "harika", "inanÄ±lmaz", "olaÄŸanÃ¼stÃ¼",
]

_BANNED_LIST_STR = ", ".join(f'"{w}"' for w in _BANNED_WORDS)


def _build_son_kontrol() -> str:
    """Section 5: SON KONTROL â€” yasaklar + kalite, 'gÃ¶ndermeden Ã¶nce kontrol et' framing."""
    return f"""## SON KONTROL â€” GÃ¶ndermeden Ã¶nce kontrol et

1. **YasaklÄ± kelimeler:** Åžu kelime/kalÄ±plarÄ± kullandÄ±ysan output geÃ§ersiz, baÅŸtan yaz:
   {_BANNED_LIST_STR}
   Emoji veya sembol de yasak. Bunlar yerine spesifik, somut, gÃ¼nlÃ¼k dilde yaz.

2. **AI testi:** Bunu gerÃ§ek bir insan tweet atar mÄ±ydÄ±? "AI yazmÄ±ÅŸ" hissi varsa baÅŸtan yaz.

3. **Ä°lk cÃ¼mle testi:** Ä°lk cÃ¼mle sÄ±radan mÄ±? SÄ±radansa deÄŸiÅŸtir.

4. **Dolgu testi:** "Bu Ã§ok Ã¶nemli bir geliÅŸme" gibi hiÃ§bir ÅŸey sÃ¶ylemeyen cÃ¼mle varsa sil.

5. **Karakter limiti:** Verilen aralÄ±kta mÄ±? DeÄŸilse dÃ¼zelt."""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# APEX SECTION (optional, appended when active)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_APEX_V3 = """## APEX MODE

Normal mod bilgi verir. Apex mod HÄ°SSETTÄ°RÄ°R.

- Ä°lk cÃ¼mle: Scroll durdurucu. Ä°ddia, Ã§eliÅŸki veya ÅŸok.
- GÃ¶vde: Her cÃ¼mle bir sonrakini okutacak tension.
- Son cÃ¼mle: Mic drop. Screenshot'lanacak kadar gÃ¼Ã§lÃ¼.
- Somut, spesifik, kiÅŸisel, beklenmedik aÃ§Ä±.
- Liste formatÄ± (1. 2. 3.) yasak. Generic tavsiye yasak.
- Birileri bunu screenshot'layÄ±p paylaÅŸÄ±r mÄ±? HayÄ±rsa baÅŸtan yaz."""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MAIN BUILDER
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def build_final_prompt_v3(
    content_type: str,
    topic: str = None,
    persona: str = "otorite",
    tone: str = "natural",
    knowledge: str = None,
    length: str = "punch",
    language: str = "auto",
    original_tweet: str = None,
    reply_mode: str = None,
    article_style: str = None,
    references: list = None,
    additional_context: str = None,
    is_apex: bool = False,
    style_prompt: str = None,
    example_tweets: list = None,
    platform: str = "twitter",
    direction: str = None,
    direction_custom: str = None,
    brand_voice: dict = None,
    # Accept but ignore v1 extras for compatibility
    **kwargs,
) -> str:
    """
    Build prompt v3: 5-section architecture.
    Same params as build_final_prompt but leaner output.
    
    Sections:
      1. GÃ–REV â€” what to produce
      2. SES â€” voice (style > persona > tone)
      3. KURALLAR â€” length, platform, language
      4. Ã–RNEKLER â€” few-shot examples (if any)
      5. SON KONTROL â€” banned words + quality checklist
    """
    sections = []

    # 1. GÃ–REV
    sections.append(_build_gorev(
        content_type=content_type,
        topic=topic,
        original_tweet=original_tweet,
        reply_mode=reply_mode,
        article_style=article_style,
        references=references,
        additional_context=additional_context,
        direction=direction,
        direction_custom=direction_custom,
    ))

    # 2. SES
    sections.append(_build_ses(
        persona=persona,
        tone=tone,
        style_prompt=style_prompt,
        platform=platform,
        content_type=content_type,
        brand_voice=brand_voice,
    ))

    # 3. KURALLAR
    sections.append(_build_kurallar(
        content_type=content_type,
        length=length,
        language=language,
        knowledge=knowledge,
        platform=platform,
    ))

    # 4. Ã–RNEKLER (optional)
    ornekler = _build_ornekler(example_tweets)
    if ornekler:
        sections.append(ornekler)

    # APEX (optional, before final check)
    if is_apex:
        sections.append(_APEX_V3)

    # 5. SON KONTROL (always last)
    sections.append(_build_son_kontrol())

    return "\n\n---\n\n".join(sections)


__all__ = ["build_final_prompt_v3", "FEW_SHOT_EXAMPLES"]
