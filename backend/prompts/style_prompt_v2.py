"""
Style Lab v2 - Style-Enhanced Prompt Builder
TÃ¼m v2 katmanlarÄ±nÄ± birleÅŸtiren prompt builder.
Mevcut build_final_prompt'a dokunmadan, style_profile aktif olduÄŸunda kullanÄ±lÄ±r.
"""


def build_style_enhanced_prompt(
    content_type: str,  # tweet, quote, reply
    topic: str,
    style_fingerprint: dict,
    viral_patterns: dict,
    constraints,  # StyleConstraints instance
    reference_tweets: list,  # RAG'den gelen tweet'ler
    persona: str = "otorite",
    tone: str = "natural",
    knowledge: str = None,
    length: str = "punch",
    language: str = "auto",
    original_tweet: str = None,
    reply_mode: str = None,
    additional_context: str = None,
    is_apex: bool = False,
    image_context: str = None,
) -> str:
    """
    Style Lab v2 prompt builder.
    Mevcut builder.py fonksiyonlarÄ±nÄ± re-use eder + v2 katmanlarÄ± ekler.
    """
    # Lazy imports (circular import Ã¶nleme)
    from .system_identity import SYSTEM_IDENTITY
    from .algorithm import (
        ALGORITHM_KNOWLEDGE, ALGORITHM_KNOWLEDGE_COMPACT,
        CTA_STRATEGIES, HOOK_FORMULAS, CONTENT_RULES,
    )
    from .quality import QUALITY_CRITERIA, APEX_MODE
    from .builder import (
        TASK_DEFINITIONS,
        build_persona_section,
        build_tone_section,
        build_knowledge_section,
        build_length_section,
        build_reply_mode_section,
    )

    sections = []

    # â”€â”€â”€ 0. HARD BLOCK (en Ã¼stte, model ilk bunu gÃ¶rmeli) â”€â”€â”€
    sections.append(_build_hard_block())

    # â”€â”€â”€ 1. SYSTEM IDENTITY â”€â”€â”€
    sections.append(SYSTEM_IDENTITY)

    # â”€â”€â”€ 2. ALGORITHM KNOWLEDGE â”€â”€â”€
    is_twitter = content_type in ("tweet", "quote", "reply")
    if is_twitter:
        sections.append(ALGORITHM_KNOWLEDGE)
        sections.append(CONTENT_RULES)
    else:
        sections.append(ALGORITHM_KNOWLEDGE_COMPACT)

    # â”€â”€â”€ 3. TASK DEFINITION â”€â”€â”€
    task = TASK_DEFINITIONS.get(content_type, TASK_DEFINITIONS["tweet"])
    if original_tweet and "{original_tweet}" in task:
        task = task.format(original_tweet=original_tweet)
    sections.append(task)

    # â”€â”€â”€ 4. STÄ°L DNA (v2 - fingerprint'ten) â”€â”€â”€
    sections.append(_build_style_dna_section(style_fingerprint))

    # â”€â”€â”€ 5. MÄ°KRO KURALLAR (v2 - somut, aksiyonel) â”€â”€â”€
    sections.append(_build_micro_rules_section(style_fingerprint))

    # â”€â”€â”€ 6. VÄ°RAL PATTERN INSIGHT'LAR (v2) â”€â”€â”€
    sections.append(_build_viral_insights_section(viral_patterns))

    # â”€â”€â”€ 7. CONSTRAINT'LER (v2 - StyleConstraints.to_prompt()) â”€â”€â”€
    if constraints:
        sections.append(constraints.to_prompt())

    # â”€â”€â”€ 8. RAG Ã–RNEKLERÄ° (v2 - engagement metadata ile) â”€â”€â”€
    sections.append(_build_rag_examples_section(reference_tweets))

    # â”€â”€â”€ 9. PERSONA + TONE â”€â”€â”€
    sections.append(build_persona_section(persona))
    if is_twitter:
        sections.append(HOOK_FORMULAS)
    sections.append(build_tone_section(tone))

    # â”€â”€â”€ 10. KNOWLEDGE MODE â”€â”€â”€
    if knowledge:
        sections.append(build_knowledge_section(knowledge))

    # â”€â”€â”€ 11. LENGTH â”€â”€â”€
    sections.append(build_length_section(content_type, length))

    # â”€â”€â”€ 12. REPLY MODE â”€â”€â”€
    if content_type == "reply" and reply_mode:
        sections.append(build_reply_mode_section(reply_mode))

    # â”€â”€â”€ 13. APEX MODE â”€â”€â”€
    if is_apex:
        sections.append(APEX_MODE)

    # â”€â”€â”€ 14. LANGUAGE â”€â”€â”€
    lang_map = {
        "auto": "Konunun diline gÃ¶re otomatik olarak TÃ¼rkÃ§e veya Ä°ngilizce yaz. Konu TÃ¼rkÃ§e ise TÃ¼rkÃ§e, Ä°ngilizce ise Ä°ngilizce.",
        "tr": "Kesinlikle TÃœRKÃ‡E yaz. TÃ¼m iÃ§erik TÃ¼rkÃ§e olmalÄ±.",
        "en": "Write in ENGLISH only. All content must be in English."
    }
    sections.append(f"## ğŸŒ DÄ°L\n\n{lang_map.get(language, lang_map['auto'])}")

    # â”€â”€â”€ 15. ADDITIONAL CONTEXT â”€â”€â”€
    combined = additional_context or ""
    if image_context:
        combined = f"{combined}\n\n{image_context}" if combined else image_context
    if combined:
        sections.append(f"## ğŸ’¡ EK BAÄLAM (KullanÄ±cÄ±dan)\n\n{combined}")

    # â”€â”€â”€ 16. TOPIC â”€â”€â”€
    if topic:
        sections.append(f"## ğŸ“Œ KONU\n\n{topic}")

    # â”€â”€â”€ 17. CTA STRATEGIES â”€â”€â”€
    sections.append(CTA_STRATEGIES)

    # â”€â”€â”€ 18. QUALITY CRITERIA â”€â”€â”€
    sections.append(QUALITY_CRITERIA)

    # â”€â”€â”€ 19. OUTPUT INSTRUCTIONS â”€â”€â”€
    sections.append("""
## Ã‡IKTI

Sadece iÃ§eriÄŸin kendisini yaz. AÃ§Ä±klama, meta bilgi, "Ä°ÅŸte tweet:" gibi giriÅŸler yasak.
Thread ise numaralandÄ±r (1/, 2/, 3/). Tek iÃ§erik ise dÃ¼z metin.
Karakter sayÄ±sÄ±nÄ± verilen aralÄ±kta tut.
Her varyant gerÃ§ekten FARKLI olsun â€” farklÄ± hook, farklÄ± aÃ§Ä±, farklÄ± yapÄ±.
""")

    return "\n\n---\n\n".join(s for s in sections if s)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# V2 SECTION BUILDERS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _build_hard_block() -> str:
    return """## MUTLAK YASAKLAR (Ä°HLAL = GEÃ‡ERSÄ°Z OUTPUT)

AÅŸaÄŸÄ±daki kelime ve kalÄ±plarÄ± Ä°Ã‡EREN herhangi bir output reddedilir:
- "devrim" (devrim niteliÄŸinde, devrim yaratÄ±yor, devrim baÅŸlatÄ±yor dahil)
- "Ã§Ä±ÄŸÄ±r aÃ§an" / "oyun deÄŸiÅŸtirici" / "game changer"
- "hazÄ±r mÄ±sÄ±nÄ±z" / "hazÄ±r mÄ±yÄ±z" / "hazÄ±r olun"
- "yeni bir dÃ¶nem" / "yeni bir Ã§aÄŸ" / "yeni bir sayfa"
- "kapÄ±larÄ± aÃ§Ä±yor" / "kapÄ±larÄ± aÃ§acak" / "kapÄ±sÄ±nÄ± aÃ§Ä±yor"
- "sÄ±nÄ±rlarÄ± zorlayan" / "sÄ±nÄ±rlarÄ± aÅŸan"
- "inovasyon" / "transformasyon" / "paradigma"
- "dÃ¼ÅŸÃ¼nmek lazÄ±m" / "dÃ¼ÅŸÃ¼nmek gerek"
- Herhangi bir emoji veya sembol
- "hadi bakalÄ±m" / "bir dÃ¼ÅŸÃ¼nÃ¼n" / "merak etmeyin"
- "siz ne dÃ¼ÅŸÃ¼nÃ¼yorsunuz"
- "muhteÅŸem" / "harika" / "inanÄ±lmaz" / "olaÄŸanÃ¼stÃ¼"

Bu listedeki hiÃ§bir kelimeyi, hiÃ§bir baÄŸlamda, hiÃ§bir ÅŸekilde kullanma.
Bunun yerine spesifik, somut, gÃ¼nlÃ¼k dilde yaz."""


def _build_style_dna_section(fp: dict) -> str:
    """Fingerprint'ten stil DNA'sÄ± Ã§Ä±kar â€” AI'Ä±n analiz etmesi iÃ§in"""
    if not fp:
        return ""

    lines = ["## ğŸ§¬ STÄ°L DNA'SI (Bu kiÅŸinin yazÄ±m kimliÄŸi â€” EN YÃœKSEK Ã–NCELÄ°K)"]
    lines.append("")
    lines.append("Bu kiÅŸi gibi yaz. AÅŸaÄŸÄ±daki DNA haritasÄ±nÄ± takip et:")
    lines.append("")

    # Ortalama uzunluk
    avg_len = fp.get('avg_length', 0)
    if avg_len:
        lines.append(f"- **Ortalama tweet uzunluÄŸu:** ~{int(avg_len)} karakter")

    # CÃ¼mle yapÄ±sÄ±
    sentence = fp.get('sentence_structure', {})
    if sentence:
        avg_sent = sentence.get('avg_sentences_per_tweet', 0)
        avg_words = sentence.get('avg_words_per_sentence', 0)
        if avg_sent:
            lines.append(f"- **CÃ¼mle/tweet:** ~{round(avg_sent, 1)} cÃ¼mle")
        if avg_words:
            lines.append(f"- **Kelime/cÃ¼mle:** ~{round(avg_words, 1)} kelime ({'kÄ±sa ve keskin' if avg_words < 8 else 'orta' if avg_words < 15 else 'uzun ve detaylÄ±'})")

    # AÃ§Ä±lÄ±ÅŸ stili
    opening = fp.get('opening_psychology', {})
    if opening:
        dom = opening.get('dominant_pattern', '')
        dist = opening.get('distribution', {})
        if dom:
            pattern_names = {
                'direct': 'Direkt statement ile aÃ§ar',
                'question': 'Soru ile aÃ§ar',
                'story': 'Hikaye/anekdot ile aÃ§ar',
                'data': 'Veri/rakam ile aÃ§ar',
                'contrast': 'ZÄ±tlÄ±k/kontrast ile aÃ§ar',
            }
            lines.append(f"- **AÃ§Ä±lÄ±ÅŸ stili:** {pattern_names.get(dom, dom)}")
            if dist:
                top3 = sorted(dist.items(), key=lambda x: x[1], reverse=True)[:3]
                dist_str = ", ".join(f"{k}: %{int(v)}" for k, v in top3)
                lines.append(f"  DaÄŸÄ±lÄ±m: {dist_str}")

    # KapanÄ±ÅŸ stili
    closing = fp.get('closing_strategy', {})
    if closing:
        dom_close = closing.get('dominant', '')
        if dom_close:
            close_names = {
                'statement': 'Net bir statement ile bitirir',
                'question': 'Soru ile bitirir (reply tetikler)',
                'open': 'AÃ§Ä±k uÃ§lu bÄ±rakÄ±r',
                'cta': 'CTA ile bitirir',
                'punchline': 'Punchline ile bitirir',
            }
            lines.append(f"- **KapanÄ±ÅŸ stili:** {close_names.get(dom_close, dom_close)}")

    # Dil karÄ±ÅŸÄ±mÄ±
    lang = fp.get('language_mix', {})
    if lang:
        style = lang.get('language_style', '')
        en_pct = lang.get('english_word_pct', 0)
        if style:
            style_names = {
                'pure_turkish': 'Saf TÃ¼rkÃ§e, Ä°ngilizce kelime yok',
                'light_english': f'TÃ¼rkÃ§e aÄŸÄ±rlÄ±klÄ±, %{int(en_pct)} Ä°ngilizce teknik terim',
                'heavy_english': f'YoÄŸun Ä°ngilizce karÄ±ÅŸÄ±mÄ± (%{int(en_pct)})',
                'code_switching': 'TÃ¼rkÃ§e-Ä°ngilizce geÃ§iÅŸli',
                'pure_english': 'Tamamen Ä°ngilizce',
            }
            lines.append(f"- **Dil:** {style_names.get(style, style)}")

    # Emoji stratejisi
    emoji = fp.get('emoji_strategy', {})
    if emoji:
        e_style = emoji.get('style', '')
        if e_style == 'no_emoji':
            lines.append("- **Emoji:** KULLANMAZ")
        elif e_style == 'light':
            top = emoji.get('top_emojis', [])[:3]
            lines.append(f"- **Emoji:** Nadiren kullanÄ±r{' (' + ' '.join(top) + ')' if top else ''}")
        elif e_style in ('moderate', 'heavy'):
            top = emoji.get('top_emojis', [])[:5]
            lines.append(f"- **Emoji:** SÄ±k kullanÄ±r{' (' + ' '.join(top) + ')' if top else ''}")

    # Noktalama DNA'sÄ±
    punct = fp.get('punctuation_dna', {})
    if punct:
        traits = []
        if punct.get('comma_per_tweet', 0) > 2:
            traits.append("virgÃ¼l sever")
        if punct.get('ellipsis_per_tweet', 0) > 0.3:
            traits.append("Ã¼Ã§ nokta kullanÄ±r")
        if punct.get('exclamation_per_tweet', 0) < 0.1:
            traits.append("Ã¼nlem kullanmaz")
        elif punct.get('exclamation_per_tweet', 0) > 1:
            traits.append("Ã¼nlem sever")
        no_punct = punct.get('tweets_ending_no_punct', 0)
        if no_punct > 50:
            traits.append("noktalama olmadan bitirir")
        if traits:
            lines.append(f"- **Noktalama:** {', '.join(traits)}")

    # BÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf
    cap = fp.get('capitalization', {})
    if cap:
        if cap.get('starts_lowercase_pct', 0) > 70:
            lines.append("- **BÃ¼yÃ¼k harf:** KÃ¼Ã§Ã¼k harfle baÅŸlar")
        if cap.get('uses_all_caps_emphasis_pct', 0) > 15:
            lines.append("- **Vurgulama:** BÃœYÃœK HARF ile vurgular")

    # SatÄ±r yapÄ±sÄ±
    line_struct = fp.get('line_structure', {})
    if line_struct:
        ml_pct = line_struct.get('multiline_pct', 0)
        if ml_pct > 50:
            avg_lines = line_struct.get('avg_lines_per_tweet', 3)
            lines.append(f"- **Format:** Ã‡ok satÄ±rlÄ± yazar (~{round(avg_lines)} satÄ±r)")
        elif ml_pct < 15:
            lines.append("- **Format:** Tek blok yazar, satÄ±r kÄ±rmaz")

    return '\n'.join(lines) if len(lines) > 3 else ""


def _build_micro_rules_section(fp: dict) -> str:
    """Somut, aksiyonel mikro kurallar"""
    if not fp:
        return ""

    rules = []

    # Kelime baÅŸÄ±na aksiyon
    sentence = fp.get('sentence_structure', {})
    avg_words = sentence.get('avg_words_per_sentence', 0)
    if avg_words:
        if avg_words < 8:
            rules.append("KÄ±sa cÃ¼mleler kur. Max 8 kelime/cÃ¼mle.")
        elif avg_words < 12:
            rules.append("Orta uzunlukta cÃ¼mleler kur. 8-12 kelime/cÃ¼mle.")
        else:
            rules.append("DetaylÄ± cÃ¼mleler kurabilirsin. 12+ kelime/cÃ¼mle OK.")

    # Hashtag
    ht = fp.get('hashtag_usage', 0)
    if ht < 0.05:
        rules.append("Hashtag KULLANMA.")
    elif ht > 0.3:
        rules.append("Hashtag kullanabilirsin (max 2).")

    # Thread eÄŸilimi
    thread_pct = fp.get('thread_ratio', 0)
    if thread_pct and thread_pct > 0.15:
        rules.append("Thread formatÄ±nÄ± tercih et, konuyu bÃ¶lÃ¼mle.")

    # Soru kullanÄ±mÄ±
    q_ratio = fp.get('question_ratio', 0)
    if q_ratio > 0.3:
        rules.append("Soru sor â€” bu kiÅŸi tweet'lerin %{:.0f}'inde soru soruyor.".format(q_ratio * 100))
    elif q_ratio < 0.1:
        rules.append("Soru sorma eÄŸilimi dÃ¼ÅŸÃ¼k. Statement aÄŸÄ±rlÄ±klÄ± yaz.")

    if not rules:
        return ""

    header = "## ğŸ“ MÄ°KRO KURALLAR (Bu kiÅŸinin yazÄ±m kalÄ±plarÄ±)\n"
    return header + '\n'.join(f"- {r}" for r in rules)


def _build_viral_insights_section(vp: dict) -> str:
    """Viral pattern'lerden insight'lar"""
    if not vp:
        return ""

    lines = ["## ğŸ”¥ VÄ°RAL PATTERN ANALÄ°ZÄ°"]
    lines.append("")

    # Viral vs flop karÅŸÄ±laÅŸtÄ±rma
    viral_len = vp.get('viral_avg_length', 0)
    flop_len = vp.get('flop_avg_length', 0)
    if viral_len and flop_len:
        if viral_len > flop_len * 1.2:
            lines.append(f"- Viral tweet'ler daha UZUN (~{int(viral_len)} vs ~{int(flop_len)} kar.) â†’ Detay ver")
        elif flop_len > viral_len * 1.2:
            lines.append(f"- Viral tweet'ler daha KISA (~{int(viral_len)} vs ~{int(flop_len)} kar.) â†’ Ã–z ol")

    # Soru etkisi
    viral_q = vp.get('viral_question_ratio', 0)
    flop_q = vp.get('flop_question_ratio', 0)
    if viral_q > flop_q + 0.1:
        lines.append(f"- Soru iÃ§eren tweet'ler daha viral (%{int(viral_q*100)} vs %{int(flop_q*100)}) â†’ Soru sor")

    # Link etkisi
    flop_link = vp.get('flop_link_ratio', 0)
    viral_link = vp.get('viral_link_ratio', 0)
    if flop_link > viral_link + 0.1:
        lines.append(f"- Link iÃ§eren tweet'ler flop ediyor (%{int(flop_link*100)}) â†’ Link KOYMA")

    # Insight'lar
    insights = vp.get('insights', [])
    for insight in insights[:5]:
        lines.append(f"- {insight}")

    return '\n'.join(lines) if len(lines) > 2 else ""


def _build_rag_examples_section(tweets: list) -> str:
    """RAG'den gelen referans tweet'ler â€” engagement metadata ile"""
    if not tweets:
        return ""

    lines = ["## ğŸ“ REFERANS TWEET'LER (Bu kiÅŸinin gerÃ§ek tweet'leri â€” engagement skoru ile)"]
    lines.append("")
    lines.append("Bu tweet'leri oku, tarzÄ± yakala, ama kopyalama. YÃ¼ksek engagement olanlarÄ±n yapÄ±sÄ±nÄ± referans al.")
    lines.append("")

    for i, tweet in enumerate(tweets[:12], 1):
        content = tweet.get('content', '') if isinstance(tweet, dict) else str(tweet)
        if len(content) > 400:
            content = content[:397] + "..."

        if isinstance(tweet, dict):
            likes = tweet.get('likes', 0) or 0
            retweets = tweet.get('retweets', 0) or 0
            replies = tweet.get('replies', 0) or 0
            algo = tweet.get('algo_score', 0) or 0
            similarity = tweet.get('similarity', 0) or tweet.get('hybrid_score', 0) or 0

            meta_parts = []
            if likes:
                meta_parts.append(f"{likes}â¤")
            if retweets:
                meta_parts.append(f"{retweets}ğŸ”")
            if replies:
                meta_parts.append(f"{replies}ğŸ’¬")
            if algo:
                meta_parts.append(f"algo:{int(algo)}")
            if similarity and isinstance(similarity, float) and similarity > 0:
                meta_parts.append(f"sim:{similarity:.2f}")

            meta = f" [{', '.join(meta_parts)}]" if meta_parts else ""
            lines.append(f"{i}. {content}{meta}")
        else:
            lines.append(f"{i}. {content}")

    return '\n'.join(lines)
