"""Creator Hub Profile â€” Master Identity, Brand Voice, Niches.

GET  /profile               â€” Profil bilgilerini getir
PUT  /profile               â€” Profil gÃ¼ncelle (Pydantic validated)
POST /profile/avatar        â€” Avatar yÃ¼kle (base64 veya URL)
GET  /profile/taxonomy      â€” Niche taxonomy listesi
POST /profile/analyze-tone  â€” Twitter'dan AI ile ton analizi
"""
from fastapi import APIRouter, Depends, HTTPException
from pydantic import BaseModel, Field, model_validator
from middleware.auth import require_auth
from datetime import datetime, timezone
from typing import Optional
import logging
import httpx
import base64
import uuid
import json

router = APIRouter(prefix="/profile", tags=["profile"])
logger = logging.getLogger(__name__)


def get_supabase():
    from server import supabase
    return supabase


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NICHE TAXONOMY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

NICHE_TAXONOMY = [
    {"slug": "ai", "label": "Yapay Zeka / AI", "emoji": "ğŸ¤–"},
    {"slug": "saas", "label": "SaaS", "emoji": "â˜ï¸"},
    {"slug": "startup", "label": "GiriÅŸimcilik", "emoji": "ğŸš€"},
    {"slug": "marketing", "label": "Dijital Pazarlama", "emoji": "ğŸ“ˆ"},
    {"slug": "crypto", "label": "Kripto / Web3", "emoji": "ğŸª™"},
    {"slug": "ecommerce", "label": "E-Ticaret", "emoji": "ğŸ›’"},
    {"slug": "design", "label": "TasarÄ±m / UI-UX", "emoji": "ğŸ¨"},
    {"slug": "dev", "label": "YazÄ±lÄ±m GeliÅŸtirme", "emoji": "ğŸ’»"},
    {"slug": "data", "label": "Veri Bilimi", "emoji": "ğŸ“Š"},
    {"slug": "content", "label": "Ä°Ã§erik Ãœretimi", "emoji": "âœï¸"},
    {"slug": "video", "label": "Video / YouTube", "emoji": "ğŸ¬"},
    {"slug": "gaming", "label": "Oyun / Gaming", "emoji": "ğŸ®"},
    {"slug": "finance", "label": "Finans / YatÄ±rÄ±m", "emoji": "ğŸ’°"},
    {"slug": "health", "label": "SaÄŸlÄ±k / Wellness", "emoji": "ğŸ¥"},
    {"slug": "fitness", "label": "Fitness / Spor", "emoji": "ğŸ’ª"},
    {"slug": "food", "label": "Yemek / Gastronomi", "emoji": "ğŸ½ï¸"},
    {"slug": "travel", "label": "Seyahat", "emoji": "âœˆï¸"},
    {"slug": "education", "label": "EÄŸitim", "emoji": "ğŸ“š"},
    {"slug": "music", "label": "MÃ¼zik", "emoji": "ğŸµ"},
    {"slug": "fashion", "label": "Moda", "emoji": "ğŸ‘—"},
    {"slug": "photography", "label": "FotoÄŸrafÃ§Ä±lÄ±k", "emoji": "ğŸ“·"},
    {"slug": "realestate", "label": "Emlak", "emoji": "ğŸ "},
    {"slug": "law", "label": "Hukuk", "emoji": "âš–ï¸"},
    {"slug": "hr", "label": "Ä°nsan KaynaklarÄ±", "emoji": "ğŸ‘¥"},
    {"slug": "sustainability", "label": "SÃ¼rdÃ¼rÃ¼lebilirlik", "emoji": "ğŸŒ±"},
    {"slug": "politics", "label": "Politika / GÃ¼ndem", "emoji": "ğŸ—³ï¸"},
    {"slug": "science", "label": "Bilim", "emoji": "ğŸ”¬"},
    {"slug": "automotive", "label": "Otomotiv", "emoji": "ğŸš—"},
    {"slug": "parenting", "label": "Ebeveynlik", "emoji": "ğŸ‘¶"},
    {"slug": "pets", "label": "Evcil Hayvanlar", "emoji": "ğŸ¾"},
    {"slug": "diy", "label": "Kendin Yap / DIY", "emoji": "ğŸ”§"},
    {"slug": "motivation", "label": "Motivasyon / KiÅŸisel GeliÅŸim", "emoji": "ğŸŒŸ"},
    {"slug": "books", "label": "Kitap / Okuma", "emoji": "ğŸ“–"},
    {"slug": "cinema", "label": "Sinema / Dizi", "emoji": "ğŸ¥"},
    {"slug": "art", "label": "Sanat", "emoji": "ğŸ–¼ï¸"},
    {"slug": "news", "label": "Habercilik", "emoji": "ğŸ“°"},
    {"slug": "security", "label": "Siber GÃ¼venlik", "emoji": "ğŸ”’"},
    {"slug": "nocode", "label": "No-Code / Low-Code", "emoji": "âš¡"},
    {"slug": "freelance", "label": "Freelance / Uzaktan Ã‡alÄ±ÅŸma", "emoji": "ğŸ¡"},
    {"slug": "community", "label": "Topluluk YÃ¶netimi", "emoji": "ğŸ¤"},
]

VALID_NICHE_SLUGS = {n["slug"] for n in NICHE_TAXONOMY}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PYDANTIC MODELS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class BrandVoiceTones(BaseModel):
    informative: int = Field(40, ge=0, le=100)
    friendly: int = Field(40, ge=0, le=100)
    witty: int = Field(20, ge=0, le=100)
    aggressive: int = Field(0, ge=0, le=100)
    inspirational: int = Field(0, ge=0, le=100)

    @model_validator(mode="after")
    def total_must_be_100(self):
        total = self.informative + self.friendly + self.witty + self.aggressive + self.inspirational
        if total != 100:
            raise ValueError(f"Ton toplamÄ± 100 olmalÄ±, ÅŸu an {total}")
        return self


class BrandVoice(BaseModel):
    tones: BrandVoiceTones = BrandVoiceTones()
    principles: list[str] = Field(default=[], max_length=5)
    avoid: list[str] = Field(default=[], max_length=5)
    sample_voice: str = Field(default="", max_length=500)

    @model_validator(mode="after")
    def clean_lists(self):
        self.principles = [p.strip()[:200] for p in self.principles if p.strip()]
        self.avoid = [a.strip()[:200] for a in self.avoid if a.strip()]
        return self


class ProfileUpdate(BaseModel):
    display_name: Optional[str] = Field(None, max_length=100)
    title: Optional[str] = Field(None, max_length=100)
    niches: list[str] = Field(default=[], max_length=10)
    brand_voice: Optional[BrandVoice] = None

    @model_validator(mode="after")
    def validate_niches(self):
        invalid = [n for n in self.niches if n not in VALID_NICHE_SLUGS]
        if invalid:
            raise ValueError(f"GeÃ§ersiz niche slug'larÄ±: {invalid}")
        return self


class AvatarUpdate(BaseModel):
    """Avatar: base64 data veya platform'dan Ã§ek."""
    source: str = Field(..., pattern="^(upload|twitter|instagram|tiktok)$")
    data: Optional[str] = None  # base64 (upload iÃ§in)
    content_type: Optional[str] = Field(None, pattern="^image/(jpeg|png|webp)$")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENDPOINTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.get("/taxonomy")
async def get_taxonomy():
    """Niche taxonomy listesi (public, auth gerektirmez)."""
    return NICHE_TAXONOMY


@router.get("")
async def get_profile(user=Depends(require_auth), supabase=Depends(get_supabase)):
    """KullanÄ±cÄ± profil bilgilerini getir."""
    result = supabase.table("user_settings") \
        .select("display_name, title, avatar_url, niches, brand_voice") \
        .eq("user_id", user.id) \
        .limit(1) \
        .execute()

    if not result.data:
        # Default profil
        return {
            "display_name": None,
            "title": None,
            "avatar_url": None,
            "niches": [],
            "brand_voice": BrandVoice().model_dump(),
        }

    profile = result.data[0]
    # brand_voice boÅŸsa default template dÃ¶ndÃ¼r
    if not profile.get("brand_voice"):
        profile["brand_voice"] = BrandVoice().model_dump()
    if not profile.get("niches"):
        profile["niches"] = []

    return profile


@router.put("")
async def update_profile(body: ProfileUpdate, user=Depends(require_auth), supabase=Depends(get_supabase)):
    """Profil gÃ¼ncelle (validated)."""
    now = datetime.now(timezone.utc).isoformat()

    update_data = {"updated_at": now}

    if body.display_name is not None:
        update_data["display_name"] = body.display_name.strip() or None
    if body.title is not None:
        update_data["title"] = body.title.strip() or None
    if body.niches is not None:
        update_data["niches"] = body.niches
    if body.brand_voice is not None:
        update_data["brand_voice"] = body.brand_voice.model_dump()

    result = supabase.table("user_settings") \
        .upsert({"user_id": user.id, **update_data}, on_conflict="user_id") \
        .execute()

    return {"success": True, "profile": result.data[0] if result.data else update_data}


@router.post("/avatar")
async def update_avatar(body: AvatarUpdate, user=Depends(require_auth), supabase=Depends(get_supabase)):
    """Avatar gÃ¼ncelle: upload (base64) veya platform'dan Ã§ek."""
    now = datetime.now(timezone.utc).isoformat()
    avatar_url = None

    if body.source == "upload":
        # Base64 upload â†’ Supabase Storage
        if not body.data:
            raise HTTPException(status_code=400, detail="Upload iÃ§in data (base64) gerekli")

        content_type = body.content_type or "image/jpeg"
        ext = content_type.split("/")[1]
        file_name = f"avatars/{user.id}/{uuid.uuid4().hex}.{ext}"

        try:
            file_bytes = base64.b64decode(body.data)
        except Exception:
            raise HTTPException(status_code=400, detail="GeÃ§ersiz base64 data")

        # Max 2MB
        if len(file_bytes) > 2 * 1024 * 1024:
            raise HTTPException(status_code=400, detail="Avatar max 2MB olabilir")

        try:
            supabase.storage.from_("public-assets").upload(
                file_name, file_bytes,
                {"content-type": content_type, "upsert": "true"}
            )
            avatar_url = f"{supabase.supabase_url}/storage/v1/object/public/public-assets/{file_name}"
        except Exception as e:
            logger.error(f"Avatar upload failed: {e}")
            raise HTTPException(status_code=500, detail="Avatar yÃ¼klenemedi")

    else:
        # Platform'dan Ã§ek
        platform = body.source  # twitter, instagram, tiktok

        # KullanÄ±cÄ±nÄ±n bu platformdaki hesabÄ±nÄ± bul
        acc = supabase.table("connected_accounts") \
            .select("username") \
            .eq("user_id", user.id) \
            .eq("platform", platform) \
            .is_("deleted_at", "null") \
            .limit(1) \
            .execute()

        if not acc.data:
            raise HTTPException(status_code=404, detail=f"{platform} hesabÄ± bulunamadÄ±")

        username = acc.data[0]["username"]
        pic_url = None

        try:
            if platform == "twitter":
                from services.twitter_scraper import scraper
                info = await scraper.get_user_info_async(username)
                if info:
                    pic_url = info.get("avatar_url") or info.get("profile_image_url", "")
                    if pic_url:
                        pic_url = pic_url.replace("_normal.", "_400x400.").replace("_normal", "_400x400")
                    # Fallback: unavatar.io
                    if not pic_url:
                        pic_url = f"https://unavatar.io/x/{username}"

            elif platform == "instagram":
                async with httpx.AsyncClient(timeout=10) as client:
                    r = await client.get(
                        f"https://www.instagram.com/api/v1/users/web_profile_info/?username={username}",
                        headers={"User-Agent": "Instagram 219.0.0.12.117", "X-IG-App-ID": "936619743392459"}
                    )
                    if r.status_code == 200:
                        data = r.json()
                        pic_url = data.get("data", {}).get("user", {}).get("profile_pic_url_hd")

            elif platform == "tiktok":
                # TikTok avatar: basit scrape, ileride geliÅŸtirilebilir
                pass

        except Exception as e:
            logger.warning(f"Avatar fetch from {platform} failed: {e}")
            raise HTTPException(status_code=502, detail=f"{platform}'dan avatar alÄ±namadÄ±")

        if not pic_url:
            raise HTTPException(status_code=404, detail=f"{platform}'da profil fotoÄŸrafÄ± bulunamadÄ±")

        # Platform avatar'Ä± kendi storage'Ä±mÄ±za kopyala (hotlink deÄŸil)
        try:
            async with httpx.AsyncClient(timeout=15, follow_redirects=True) as client:
                img_resp = await client.get(pic_url)
                img_resp.raise_for_status()

            img_bytes = img_resp.content
            ct = img_resp.headers.get("content-type", "image/jpeg")
            ext = "jpg" if "jpeg" in ct else ("png" if "png" in ct else "webp")
            file_name = f"avatars/{user.id}/{uuid.uuid4().hex}.{ext}"

            supabase.storage.from_("public-assets").upload(
                file_name, img_bytes,
                {"content-type": ct, "upsert": "true"}
            )
            avatar_url = f"{supabase.supabase_url}/storage/v1/object/public/public-assets/{file_name}"
        except Exception as e:
            logger.error(f"Avatar storage copy failed: {e}")
            raise HTTPException(status_code=500, detail="Avatar kaydedilemedi")

    # DB gÃ¼ncelle
    supabase.table("user_settings") \
        .upsert({"user_id": user.id, "avatar_url": avatar_url, "updated_at": now}, on_conflict="user_id") \
        .execute()

    return {"success": True, "avatar_url": avatar_url}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AI TONE ANALYSIS (Twitter â†’ Brand Voice)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class DnaTestRequest(BaseModel):
    tones: dict = {}
    principles: list = []
    avoid: list = []


@router.post("/dna-test")
async def dna_test(body: DnaTestRequest, user=Depends(require_auth)):
    """DNA ile Ã¶rnek tweet Ã¼ret â€” instant gratification."""
    from server import openai_client

    tone_labels = {"informative": "Bilgi Verici", "friendly": "Samimi", "witty": "Esprili",
                   "aggressive": "Agresif", "inspirational": "Ä°lham Verici"}
    active = {k: v for k, v in body.tones.items() if v and v > 0}
    sorted_t = sorted(active.items(), key=lambda x: -x[1])
    tone_str = ", ".join(f"%{v} {tone_labels.get(k, k)}" for k, v in sorted_t[:3])

    # Niche context
    sb = get_supabase()
    profile = sb.table("user_settings").select("niches").eq("user_id", user.id).limit(1).execute()
    niches = profile.data[0].get("niches", []) if profile.data else []

    # GerÃ§ek trend Ã§ek (niche'e gÃ¶re filtreli)
    import random
    from datetime import timedelta
    from routes.trends import NICHE_KEYWORDS

    cutoff = (datetime.now(timezone.utc) - timedelta(hours=48)).isoformat()
    trend_query = supabase.table("trends") \
        .select("topic, summary, keywords") \
        .eq("is_visible", True) \
        .gte("created_at", cutoff) \
        .gte("score", 60) \
        .order("score", desc=True) \
        .limit(20) \
        .execute()

    all_trends = trend_query.data or []
    chosen_trend = None

    if all_trends and niches:
        niche_kws = []
        for n in niches:
            niche_kws.extend(NICHE_KEYWORDS.get(n, []))
        niche_kws_lower = [kw.lower() for kw in niche_kws]

        matching = [t for t in all_trends if any(
            nk in (t.get("topic", "") + " ".join(t.get("keywords", []))).lower()
            for nk in niche_kws_lower
        )]
        if matching:
            chosen_trend = random.choice(matching[:5])

    if not chosen_trend and all_trends:
        chosen_trend = random.choice(all_trends[:5])

    if chosen_trend:
        topic_str = chosen_trend["topic"]
        trend_context = f'GÃ¼ncel trend: "{chosen_trend["topic"]}". Ã–zet: {chosen_trend.get("summary", "")}'
    else:
        niche_labels = {n["slug"]: n["label"] for n in NICHE_TAXONOMY}
        fallback_niche = random.choice(niches) if niches else "teknoloji"
        topic_str = niche_labels.get(fallback_niche, fallback_niche)
        trend_context = f'Konu: {topic_str}'

    avoid_str = ', '.join(body.avoid[:5]) if body.avoid else ''
    principles_str = ', '.join(body.principles[:5]) if body.principles else ''

    # Tone voice guides (dominant tonlarÄ±n ses kÄ±lavuzu)
    from prompts.builder_v3 import TONE_VOICE_GUIDES, CONTENT_ARCHITECTURE
    sorted_t = sorted(active.items(), key=lambda x: -x[1])
    voice_section = ""
    for key, val in sorted_t[:2]:
        guide = TONE_VOICE_GUIDES.get(key)
        if guide:
            voice_section += f"\n**ANA TON: %{val} {guide['label']}**\nSes: {guide['voice']}\nHook: {guide['hook']}\n"

    # Sentez ipucu
    if len(sorted_t) >= 2:
        l1 = TONE_VOICE_GUIDES.get(sorted_t[0][0], {}).get("label", sorted_t[0][0])
        l2 = TONE_VOICE_GUIDES.get(sorted_t[1][0], {}).get("label", sorted_t[1][0])
        voice_section += f"\nSENTEZ: {l1} + {l2} = tek bir ruh hali. Bipolar davranma.\n"

    try:
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": f"""KullanÄ±cÄ±nÄ±n marka sesiyle, gÃ¼ncel bir trend hakkÄ±nda tek bir tweet Ã¼ret.

{trend_context}

{voice_section}

{f'ZORUNLU Ä°LKELER: {principles_str}' if principles_str else ''}
{f'KULLANICI YASAKLARI: {avoid_str}' if avoid_str else ''}

{CONTENT_ARCHITECTURE}

KIRILMAZ YASAKLAR:
- Emoji YASAK. Hashtag YASAK.
- AI ÅŸablon kalÄ±plarÄ± YASAK ("UnutmayÄ±n", "SonuÃ§ olarak", "Ä°ÅŸte size")
- Ucuz etkileÅŸim tuzaklarÄ± YASAK ("Siz ne dÃ¼ÅŸÃ¼nÃ¼yorsunuz?", "KatÄ±lÄ±yor musunuz?")
- Genel geÃ§er konular YASAK (kahve, ofis, pazartesi)
- Ana fikri Ã¶zetleme. Tespit et ve BIRAK.
- Clickbait, Ã¼Ã§ nokta, "Ä°ÅŸin sÄ±rrÄ±..." YASAK.

ZORUNLU:
- Max 280 karakter
- Sadece tweet metnini dÃ¶ndÃ¼r"""},
                {"role": "user", "content": f'{trend_context}\n\nBu trend hakkÄ±nda DNA ile bir tweet Ã¼ret.'}
            ],
            temperature=0.85,
            max_tokens=150,
        )
        content = response.choices[0].message.content.strip().strip('"')
        return {
            "success": True,
            "content": content,
            "trend_topic": chosen_trend["topic"] if chosen_trend else None,
        }
    except Exception as e:
        logger.error(f"DNA test error: {e}")
        raise HTTPException(status_code=500, detail="Ã–rnek Ã¼retilemedi")


class AnalyzeToneRequest(BaseModel):
    twitter_username: Optional[str] = None  # BoÅŸsa baÄŸlÄ± hesaptan alÄ±r


@router.post("/analyze-tone")
async def analyze_tone(body: AnalyzeToneRequest = AnalyzeToneRequest(), user=Depends(require_auth), supabase=Depends(get_supabase)):
    """Twitter tweetlerinden AI ile marka tonu analizi.
    Son 50 tweeti okur, 5 ton ekseninde yÃ¼zdelik daÄŸÄ±lÄ±m dÃ¶ner.
    """
    from server import openai_client
    from services.twitter_scraper import scraper

    # Username belirle
    username = body.twitter_username
    if not username:
        acc = supabase.table("connected_accounts") \
            .select("username") \
            .eq("user_id", user.id) \
            .eq("platform", "twitter") \
            .is_("deleted_at", "null") \
            .limit(1) \
            .execute()
        if not acc.data:
            raise HTTPException(status_code=404, detail="BaÄŸlÄ± Twitter hesabÄ± bulunamadÄ±. Ã–nce bir hesap ekleyin.")
        username = acc.data[0]["username"]

    username = username.lstrip("@").strip()
    if not username:
        raise HTTPException(status_code=400, detail="GeÃ§erli bir kullanÄ±cÄ± adÄ± gerekli")

    # Tweetleri Ã§ek
    try:
        tweets = await scraper.get_user_tweets_async(username, count=50)
    except Exception as e:
        logger.error(f"Tweet fetch failed for @{username}: {e}")
        raise HTTPException(status_code=502, detail="Tweetler alÄ±namadÄ±, lÃ¼tfen tekrar deneyin")

    if not tweets or len(tweets) < 5:
        raise HTTPException(status_code=422, detail=f"@{username} iÃ§in yeterli tweet bulunamadÄ± (min 5)")

    tweet_texts = [t.get("content", "") for t in tweets if t.get("content", "").strip()]
    tweet_block = "\n---\n".join(tweet_texts[:50])

    # GPT ile ton analizi
    try:
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": """Sen uzman bir sosyal medya ton analistisin.
Verilen tweetleri analiz edip yazarÄ±n iletiÅŸim tonunu 5 eksende yÃ¼zdelik olarak belirle.

5 EKSEN:
1. informative: Bilgi verici, Ã¶ÄŸretici, veri odaklÄ±
2. friendly: Samimi, sÄ±cak, yakÄ±n, kiÅŸisel
3. witty: Esprili, keskin, mizahi, alaycÄ±
4. aggressive: Agresif, provokatif, sert, direkt
5. inspirational: Ä°lham verici, motive edici, vizyoner

KURALLAR:
- Toplam TAM 100 olmalÄ±
- Her deÄŸer 0-100 arasÄ±, 5'in katÄ±
- En az 2 eksen 0'dan bÃ¼yÃ¼k olmalÄ±
- Tweetlerdeki gerÃ§ek tona bak, ne sÃ¶ylediklerine deÄŸil nasÄ±l sÃ¶ylediklerine

AyrÄ±ca kÄ±sa bir "insight" yaz: YazarÄ±n farkÄ±nda olmayabileceÄŸi bir ton Ã¶zelliÄŸi. ÅaÅŸÄ±rtÄ±cÄ±, kÄ±ÅŸkÄ±rtÄ±cÄ± ve eÄŸlenceli olsun. TÃ¼rkÃ§e yaz.

JSON formatÄ±nda dÃ¶ndÃ¼r:
{
  "tones": {"informative": 25, "friendly": 30, "witty": 35, "aggressive": 5, "inspirational": 5},
  "insight": "Sen kendini ciddi sanÄ±yorsun ama tweetlerinin %70'i espri kokan cÃ¼mlelerle baÅŸlÄ±yor!",
  "dominant": "witty"
}"""},
                {"role": "user", "content": f"@{username} kullanÄ±cÄ±sÄ±nÄ±n son {len(tweet_texts)} tweeti:\n\n{tweet_block}"}
            ],
            temperature=0.3,
            response_format={"type": "json_object"}
        )

        result = json.loads(response.choices[0].message.content)
        tones = result.get("tones", {})

        # Validasyon: toplam 100 olmalÄ±
        total = sum(tones.values())
        if total != 100:
            # Normalize et
            factor = 100 / max(total, 1)
            tones = {k: max(0, round(v * factor / 5) * 5) for k, v in tones.items()}
            # FarkÄ± en bÃ¼yÃ¼k deÄŸere ekle/Ã§Ä±kar
            diff = 100 - sum(tones.values())
            if diff != 0:
                max_key = max(tones, key=tones.get)
                tones[max_key] += diff

        return {
            "success": True,
            "username": username,
            "tones": tones,
            "insight": result.get("insight", ""),
            "dominant": result.get("dominant", ""),
            "tweets_analyzed": len(tweet_texts),
        }

    except json.JSONDecodeError:
        raise HTTPException(status_code=500, detail="AI analiz sonucu okunamadÄ±")
    except Exception as e:
        logger.error(f"Tone analysis AI error: {e}")
        raise HTTPException(status_code=500, detail="Ton analizi baÅŸarÄ±sÄ±z oldu")
