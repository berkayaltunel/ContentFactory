"""Hesap analizi route'larÄ±.
POST /api/analyze/account - Twitter hesap analizi
GET /api/analyze/history - GeÃ§miÅŸ analizler
"""
from fastapi import APIRouter, HTTPException, Depends, Query
from middleware.auth import require_auth
from pydantic import BaseModel
from typing import Optional, List
from datetime import datetime, timezone
import uuid
import logging

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/analyze", tags=["analysis"])


class AccountAnalysisRequest(BaseModel):
    twitter_username: str
    language: str = "auto"


class GeneratedContent(BaseModel):
    content: str
    variant_index: int = 0
    character_count: int = 0


def get_supabase():
    from server import supabase
    return supabase


@router.post("/account")
async def analyze_account(request: AccountAnalysisRequest, user=Depends(require_auth)):
    """Twitter hesabÄ±nÄ± analiz et"""
    try:
        from server import openai_client
        from services.twitter_scraper import scraper

        sb = get_supabase()
        username = request.twitter_username.lstrip('@')

        # KullanÄ±cÄ± bilgisi Ã§ek (async, GraphQL fallback destekli)
        user_info = await scraper.get_user_info_async(username)
        if not user_info:
            raise HTTPException(status_code=404, detail=f"@{username} bulunamadÄ±")

        # Tweet'leri Ã§ek (async, GraphQL fallback destekli)
        tweets = await scraper.get_user_tweets_async(username, count=200)

        # AI analizi: tweet metni + engagement verileri
        tweet_lines = []
        for t in tweets[:100]:
            text = t.get('content', '')
            likes = t.get('likes', 0)
            rts = t.get('retweets', 0)
            replies = t.get('replies', 0)
            tweet_lines.append(f"[â¤ï¸{likes} ğŸ”{rts} ğŸ’¬{replies}] {text}")
        tweet_summary = "\n---\n".join(tweet_lines)
        
        # Engagement ortalamalarÄ± hesapla
        total_likes = sum(t.get('likes', 0) for t in tweets)
        total_rts = sum(t.get('retweets', 0) for t in tweets)
        total_replies = sum(t.get('replies', 0) for t in tweets)
        avg_likes = total_likes / max(len(tweets), 1)
        avg_rts = total_rts / max(len(tweets), 1)

        lang = "TÃ¼rkÃ§e" if request.language != "en" else "English"

        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": f"""Sen bir sosyal medya analistisin. Twitter hesabÄ±nÄ± derinlemesine analiz et.
{lang} yaz.

JSON formatÄ±nda dÃ¶ndÃ¼r. HER ALAN ZORUNLU:
{{
  "overall_score": 0-100 arasÄ± genel skor (integer),
  "summary": "Genel profil deÄŸerlendirmesi (3-5 cÃ¼mle)",
  "dimensions": {{
    "content_quality": 0-100,
    "engagement_rate": 0-100,
    "consistency": 0-100,
    "creativity": 0-100,
    "community": 0-100,
    "growth_potential": 0-100
  }},
  "strengths": [
    {{"title": "GÃ¼Ã§lÃ¼ yÃ¶n baÅŸlÄ±ÄŸÄ±", "description": "DetaylÄ± aÃ§Ä±klama"}},
    ...en az 3 tane
  ],
  "weaknesses": [
    {{"title": "ZayÄ±f yÃ¶n baÅŸlÄ±ÄŸÄ±", "description": "DetaylÄ± aÃ§Ä±klama"}},
    ...en az 3 tane
  ],
  "recommendations": [
    {{"title": "Ã–neri baÅŸlÄ±ÄŸÄ±", "description": "DetaylÄ± aÃ§Ä±klama"}},
    ...en az 3 tane
  ],
  "tone_analysis": "HesabÄ±n genel tonu ve iletiÅŸim stili analizi (2-3 cÃ¼mle)",
  "posting_frequency": "PaylaÅŸÄ±m sÄ±klÄ±ÄŸÄ± ve dÃ¼zeni analizi (2-3 cÃ¼mle)",
  "hashtag_strategy": "Hashtag kullanÄ±m analizi ve Ã¶neriler (2-3 cÃ¼mle)",
  "growth_tips": "BÃ¼yÃ¼me stratejisi ve Ã¶neriler (3-5 cÃ¼mle)",
  "top_tweets": [
    {{"content": "Tweet metni", "likes": 123, "retweets": 45, "replies": 10, "why_good": "Neden iyi performans gÃ¶sterdi"}},
    ...en iyi 3-5 tweet
  ]
}}

SKORLAMA:
- 80+: Profesyonel, tutarlÄ±, yÃ¼ksek etkileÅŸim
- 60-79: Ä°yi ama geliÅŸtirilebilir
- 40-59: Orta, ciddi eksikler var
- <40: BaÅŸlangÄ±Ã§ seviyesi veya inaktif"""},
                {"role": "user", "content": f"""Hesap: @{username}
Ä°sim: {user_info.get('name', 'N/A')}
Bio: {user_info.get('bio', 'N/A')}
TakipÃ§i: {user_info.get('followers', 0):,}
Takip: {user_info.get('following', 0):,}
Toplam tweet: {user_info.get('tweet_count', 0):,}
Verified: {'Evet' if user_info.get('is_verified') else 'HayÄ±r'}

Analiz edilen tweet sayÄ±sÄ±: {len(tweets)}
Ortalama like: {avg_likes:.1f}
Ortalama RT: {avg_rts:.1f}
Toplam like: {total_likes:,}

Son {len(tweets)} tweet (engagement verileriyle):
{tweet_summary}"""}
            ],
            temperature=0.5,
            response_format={"type": "json_object"}
        )

        import json
        analysis = json.loads(response.choices[0].message.content)

        # VeritabanÄ±na kaydet
        record = {
            "id": str(uuid.uuid4()),
            "user_id": user.id,
            "twitter_username": username,
            "display_name": user_info.get('name', ''),
            "bio": user_info.get('bio', ''),
            "followers_count": user_info.get('followers', 0),
            "following_count": user_info.get('following', 0),
            "tweet_count": len(tweets),
            "analysis": analysis,
            "top_tweets": sorted(tweets, key=lambda t: t.get('likes', 0), reverse=True)[:5],
            "strengths": analysis.get("strengths", []),
            "weaknesses": analysis.get("weaknesses", []),
            "recommendations": analysis.get("recommendations", []),
            "posting_patterns": analysis.get("posting_patterns", {}),
            "created_at": datetime.now(timezone.utc).isoformat()
        }

        try:
            sb.table("account_analyses").insert(record).execute()
        except Exception as db_err:
            logger.warning(f"DB insert failed (table may not exist): {db_err}")

        return {
            "success": True,
            "username": username,
            "display_name": user_info.get('name', ''),
            "followers": user_info.get('followers', 0),
            "bio": user_info.get('bio', ''),
            "tweets_analyzed": len(tweets),
            "tweet_count_analyzed": len(tweets),
            "analysis": analysis
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Account analysis error: {e}")
        raise HTTPException(status_code=500, detail="Bir hata oluÅŸtu")


@router.get("/history")
async def get_analysis_history(limit: int = Query(20, le=100), user=Depends(require_auth)):
    """GeÃ§miÅŸ analizleri getir"""
    try:
        sb = get_supabase()
        result = sb.table("account_analyses").select("*").eq("user_id", user.id).order("created_at", desc=True).limit(limit).execute()
        return result.data
    except Exception as e:
        logger.error(f"Analysis history error: {e}")
        return []
