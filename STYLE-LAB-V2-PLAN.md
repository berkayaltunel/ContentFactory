# Style Lab v2: Hibrit Stil Klonlama + Algoritma Entegrasyonu

## Vizyon
KullanÄ±cÄ±nÄ±n Twitter stilini "tÄ±pa tÄ±p" klonlayan, X algoritmasÄ±nÄ± bilen, 
en viral tweet formatlarÄ±nÄ± Ã¼reten tam otomatik sistem.

**Mevcut:** 50 tweet â†’ soyut AI analizi â†’ genel stil prompt â†’ tek variant
**Hedef:** 500+ tweet â†’ mikro-dilbilim + AI DNA + algoritma skoru â†’ akÄ±llÄ± RAG â†’ Maverick fine-tuned â†’ 5 variant â†’ ranking â†’ en iyi 2-3

---

## Sprint PlanÄ±

### Sprint 0: Veri Toplama GÃ¼Ã§lendirmesi (0.5 gÃ¼n)
**AmaÃ§:** 50 tweet yerine 500+ tweet Ã§ekmek

**GÃ¶revler:**
- [ ] `services/tweet_collector.py` oluÅŸtur (Apify entegrasyonu)
- [ ] Apify `apidojo/tweet-scraper` ile kullanÄ±cÄ± tweet'lerini Ã§ek
  - `from:handle -filter:retweets min_faves:10` (dÃ¼ÅŸÃ¼k eÅŸik, tÃ¼m karakteristik tweet'ler)
  - `from:handle filter:replies` (reply stilini de al)
  - `from:handle filter:quote` (quote tweet stilini de al)
- [ ] Limit: 500 tweet (ana) + 100 reply + 100 quote = **700 tweet**
- [ ] Maliyet: ~$0.28 per kullanÄ±cÄ± (700 tweet Ã— $0.40/1K)
- [ ] `source_tweets` tablosuna kaydet (mevcut tablo, yeni alanlar ekle)
- [ ] Yeni alanlar: `tweet_type` (original/reply/quote), `engagement_score`, `algo_score`

**Teknik Detaylar:**
```python
# Apify query'leri (3 ayrÄ± run)
queries = [
    f"from:{handle} -filter:retweets -filter:replies min_faves:10",  # Ana tweet'ler
    f"from:{handle} filter:replies min_faves:5",                      # Reply'lar
    f"from:{handle} filter:quote min_faves:5",                        # Quote tweet'ler
]
```

**DB Migration:**
```sql
-- 007_style_lab_v2.sql
ALTER TABLE source_tweets ADD COLUMN IF NOT EXISTS tweet_type TEXT DEFAULT 'original';
ALTER TABLE source_tweets ADD COLUMN IF NOT EXISTS engagement_score FLOAT;
ALTER TABLE source_tweets ADD COLUMN IF NOT EXISTS algo_score FLOAT;
ALTER TABLE source_tweets ADD COLUMN IF NOT EXISTS embedding vector(1536);
ALTER TABLE source_tweets ADD COLUMN IF NOT EXISTS word_count INT;
ALTER TABLE source_tweets ADD COLUMN IF NOT EXISTS has_link BOOLEAN DEFAULT FALSE;
ALTER TABLE source_tweets ADD COLUMN IF NOT EXISTS has_media BOOLEAN DEFAULT FALSE;
ALTER TABLE source_tweets ADD COLUMN IF NOT EXISTS language TEXT;

CREATE INDEX IF NOT EXISTS idx_source_tweets_embedding 
  ON source_tweets USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
CREATE INDEX IF NOT EXISTS idx_source_tweets_source_engagement 
  ON source_tweets (source_id, engagement_score DESC);
```

---

### Sprint 1: Algoritma Skoru Hesaplama (0.5 gÃ¼n)
**AmaÃ§:** Her tweet'e X algoritma uyumluluk skoru vermek

**GÃ¶revler:**
- [ ] `services/algo_scorer.py` oluÅŸtur
- [ ] Her tweet iÃ§in algoritma skoru hesapla (0-100 arasÄ±):

**Skor BileÅŸenleri:**
```python
def calculate_algo_score(tweet: dict) -> float:
    score = 50  # BaÅŸlangÄ±Ã§
    
    # 1. Reply tetikleme potansiyeli (+0-15)
    # Soru iÅŸareti varsa, tartÄ±ÅŸma aÃ§Ä±yorsa, gÃ¶rÃ¼ÅŸ bildiriyorsa
    if has_question(tweet): score += 8
    if has_opinion(tweet): score += 5
    if has_call_to_action(tweet): score += 7
    
    # 2. Dwell time potansiyeli (+0-15)
    # Uzunluk + bilgi yoÄŸunluÄŸu + okunabilirlik
    word_count = len(tweet['content'].split())
    if 20 <= word_count <= 60: score += 10  # Optimal uzunluk
    if has_line_breaks(tweet): score += 5    # Okunabilirlik
    
    # 3. Link cezasÄ± (-20)
    if has_external_link(tweet): score -= 20  # %50-90 eriÅŸim kaybÄ±
    
    # 4. Dil tutarlÄ±lÄ±ÄŸÄ± (+0-10)
    if is_language_consistent(tweet): score += 10
    # KarÄ±ÅŸÄ±k dil: -5, bilinmeyen dil: -30
    
    # 5. Self-contained (+0-10)
    # Bilgiyi direkt veriyor mu, link'e yÃ¶nlendirmiyor mu?
    if is_self_contained(tweet): score += 10
    
    # 6. Engagement kanÄ±tÄ± (+0-15)
    # GerÃ§ek engagement verisi varsa (reply/like oranÄ±)
    reply_ratio = tweet.get('replies', 0) / max(tweet.get('likes', 1), 1)
    if reply_ratio > 0.05: score += 10  # Reply oranÄ± yÃ¼ksek = iyi
    if reply_ratio > 0.15: score += 5   # Ã‡ok yÃ¼ksek reply = harika
    
    # 7. Bookmark potansiyeli (+0-10)
    # Liste, nasÄ±l yapÄ±lÄ±r, kaynak, bilgi deposu
    if has_save_worthy_content(tweet): score += 10
    
    return min(max(score, 0), 100)
```

- [ ] TÃ¼m `source_tweets`'e algo_score yaz
- [ ] Viral pattern extraction: En yÃ¼ksek algo_score'lu tweet'lerin ortak Ã¶zellikleri

**Viral Pattern Extraction:**
```python
def extract_viral_patterns(tweets: List[dict]) -> dict:
    """Top %20 vs bottom %20 karÅŸÄ±laÅŸtÄ±rma"""
    sorted_tweets = sorted(tweets, key=lambda t: t['engagement_score'], reverse=True)
    top_20 = sorted_tweets[:len(sorted_tweets)//5]
    bottom_20 = sorted_tweets[-len(sorted_tweets)//5:]
    
    patterns = {
        "viral_avg_length": avg_length(top_20),
        "flop_avg_length": avg_length(bottom_20),
        "viral_question_ratio": question_ratio(top_20),
        "flop_question_ratio": question_ratio(bottom_20),
        "viral_emoji_ratio": emoji_ratio(top_20),
        "flop_emoji_ratio": emoji_ratio(bottom_20),
        "viral_line_break_ratio": linebreak_ratio(top_20),
        "flop_line_break_ratio": linebreak_ratio(bottom_20),
        "viral_link_ratio": link_ratio(top_20),
        "flop_link_ratio": link_ratio(bottom_20),
        "viral_opening_patterns": analyze_openings(top_20),  # Ä°lk 5 kelime pattern
        "flop_opening_patterns": analyze_openings(bottom_20),
        "viral_time_distribution": time_distribution(top_20),  # Saat daÄŸÄ±lÄ±mÄ±
        "optimal_posting_hours": best_hours(top_20),
    }
    return patterns
```

---

### Sprint 2: Mikro-Dilbilim v2 (1 gÃ¼n)
**AmaÃ§:** Mevcut style_analyzer.py'Ä± gÃ¼Ã§lendirmek

**GÃ¶revler:**
- [ ] Mevcut 15 analiz fonksiyonunu koru (backward compatible)
- [ ] 8 yeni analiz ekle:

**Yeni Analizler:**
```python
# 1. AÃ§Ä±lÄ±ÅŸ Psikolojisi (opening_psychology)
def _opening_psychology(self, contents):
    """Ä°lk cÃ¼mlenin psikolojik tetikleyicisi"""
    patterns = {
        'question': 0,       # "HiÃ§ dÃ¼ÅŸÃ¼ndÃ¼nÃ¼z mÃ¼..."
        'bold_claim': 0,     # "X aslÄ±nda Y'dir"
        'story': 0,          # "GeÃ§en gÃ¼n...", "3 yÄ±l Ã¶nce..."
        'data': 0,           # Rakamla aÃ§Ä±lÄ±ÅŸ "Ä°nsanlarÄ±n %73'Ã¼..."
        'provocation': 0,    # "Kimse bunu konuÅŸmuyor ama..."
        'direct_address': 0, # "Sana bir ÅŸey sÃ¶yleyeyim"
        'contrast': 0,       # "Herkes X diyor ama..."
        'mystery': 0,        # "Bir sÄ±r vereyim..."
    }
    # Her tweet'in ilk cÃ¼mlesini analiz et, pattern'e gÃ¶re sÄ±nÄ±fla
    return patterns, dominant_pattern, distribution

# 2. KapanÄ±ÅŸ Stratejisi (closing_strategy)
def _closing_strategy(self, contents):
    """Tweet nasÄ±l bitiyor? CTA, soru, statement, incomplete?"""
    patterns = {
        'question_cta': 0,    # "Sen ne dÃ¼ÅŸÃ¼nÃ¼yorsun?"
        'statement': 0,       # Kesin bir ifade ile bitiÅŸ
        'incomplete': 0,      # "..." ile bitiÅŸ (merak)
        'emoji_close': 0,     # Emoji ile bitiÅŸ
        'no_close': 0,        # Ani bitiÅŸ, noktalama yok
        'call_to_action': 0,  # "RT/Like/Kaydet" (algoritma sever)
    }
    return patterns

# 3. DÃ¼ÅŸÃ¼nce YapÄ±sÄ± (thought_structure)
def _thought_structure(self, contents):
    """Bilgiyi nasÄ±l organize ediyor?"""
    return {
        'conclusion_first_pct': 0,  # SonuÃ§tan baÅŸlayÄ±p aÃ§Ä±klama
        'buildup_pct': 0,           # YavaÅŸ yavaÅŸ sonuca varma
        'list_format_pct': 0,       # Madde madde
        'single_thought_pct': 0,    # Tek cÃ¼mle, tek dÃ¼ÅŸÃ¼nce
        'multi_thought_pct': 0,     # Birden fazla baÄŸlantÄ±lÄ± dÃ¼ÅŸÃ¼nce
        'contrast_pct': 0,          # X ama Y, X deÄŸil Y
    }

# 4. Duygusal YoÄŸunluk (emotional_intensity)
def _emotional_intensity(self, contents):
    """YazÄ±m ne kadar duygusal vs rasyonel?"""
    return {
        'intensity_score': 0-100,     # 0=soÄŸukkanlÄ±, 100=ateÅŸli
        'dominant_emotion': '',        # 'analytical', 'passionate', 'humorous', 'cynical'
        'exclamation_density': 0,
        'caps_emphasis_density': 0,
        'emoji_emotional_weight': 0,
        'power_words_ratio': 0,        # GÃ¼Ã§lÃ¼ kelimeler oranÄ±
    }

# 5. Okuyucu Ä°liÅŸkisi (reader_relationship)
def _reader_relationship(self, contents):
    """Okuyucuyla nasÄ±l bir iliÅŸki kuruyor?"""
    return {
        'uses_you': 0,          # "Sen", "siz" kullanÄ±mÄ±
        'uses_we': 0,           # "Biz" kullanÄ±mÄ±
        'uses_i': 0,            # "Ben" kullanÄ±mÄ±
        'direct_address_pct': 0, # DoÄŸrudan okuyucuya hitap
        'inclusive_pct': 0,      # Okuyucuyu dahil etme
        'authority_pct': 0,      # Uzman/otorite pozisyonu
        'peer_pct': 0,          # EÅŸit seviye
    }

# 6. Tekrar KalÄ±plarÄ± (repetition_patterns)
def _repetition_patterns(self, contents):
    """KiÅŸinin tekrar kullandÄ±ÄŸÄ± yapÄ±lar"""
    return {
        'signature_openings': [],   # En sÄ±k kullanÄ±lan aÃ§Ä±lÄ±ÅŸ kalÄ±plarÄ±
        'signature_closings': [],   # En sÄ±k kullanÄ±lan kapanÄ±ÅŸ kalÄ±plarÄ±
        'filler_words': [],         # Dolgu kelimeleri (yani, iÅŸte, aslÄ±nda)
        'transition_words': [],     # GeÃ§iÅŸ kelimeleri (ama, ancak, fakat)
        'catchphrases': [],         # SÄ±k tekrarlanan ifadeler (2+ kez)
    }

# 7. Format Tercihleri (format_preferences)
def _format_preferences(self, contents):
    """GÃ¶rsel format tercihleri"""
    return {
        'uses_bullet_points': 0,
        'uses_numbered_lists': 0,
        'uses_dashes': 0,
        'uses_arrows': 0,           # â†’ â† â†‘ â†“
        'uses_separators': 0,       # --- veya ___
        'uses_parenthetical': 0,    # (parantez iÃ§i aÃ§Ä±klama)
        'uses_quotes': 0,           # "alÄ±ntÄ±" kullanÄ±mÄ±
        'thread_style': '',         # Tek tweet mi, thread mÄ±
    }

# 8. Reply/Quote Stili (interaction_style)
def _interaction_style(self, reply_tweets, quote_tweets):
    """Reply ve quote tweet'lerdeki farklÄ± stil"""
    return {
        'reply_avg_length': 0,
        'reply_tone': '',           # Daha samimi mi, formal mi?
        'reply_emoji_change': 0,    # Reply'larda emoji kullanÄ±mÄ± farkÄ±
        'quote_adds_opinion': 0,    # Quote'ta fikir mi ekliyor?
        'quote_adds_context': 0,    # Quote'ta baÄŸlam mÄ± ekliyor?
        'quote_adds_humor': 0,      # Quote'ta espri mi yapÄ±yor?
    }
```

- [ ] `generate_style_prompt` v2: Somut kurallar Ã¼ret
  - "VirgÃ¼l az kullan" â†’ "VirgÃ¼l KULLANMA. KÄ±sa cÃ¼mleler kur. Nokta ile bitir."
  - "Emoji az kullan" â†’ "Sadece ÅŸu emojileri kullan: ğŸ”¥ ğŸ’¡. BaÅŸka emoji YASAK."
- [ ] YasaklÄ± kalÄ±plar (negative rules): KiÅŸinin ASLA yapmadÄ±ÄŸÄ± ÅŸeyleri tespit et
  - "ASLA hashtag kullanma" (eÄŸer hiÃ§ kullanmÄ±yorsa)
  - "ASLA link paylaÅŸma" 
  - "ASLA emoji kullanma"

---

### Sprint 3: Embedding & RAG v2 (1 gÃ¼n)
**AmaÃ§:** Topic'e en uygun + en viral Ã¶rnekleri akÄ±llÄ± seÃ§me

**GÃ¶revler:**
- [ ] TÃ¼m source_tweets'e embedding oluÅŸtur (OpenAI text-embedding-3-small)
- [ ] Supabase pgvector'a kaydet
- [ ] `services/style_rag.py` oluÅŸtur

**AkÄ±llÄ± RAG SeÃ§imi:**
```python
async def get_style_examples(
    topic: str, 
    source_id: str, 
    limit: int = 8,
    strategy: str = "hybrid"  # "similarity", "viral", "hybrid"
) -> List[dict]:
    """Topic + engagement + algo_score hibrit seÃ§im"""
    
    # 1. Topic benzerliÄŸi ile 20 aday Ã§ek (pgvector cosine)
    topic_embedding = await get_embedding(topic)
    candidates = supabase.rpc('match_source_tweets', {
        'query_embedding': topic_embedding,
        'source_id': source_id,
        'match_count': 20,
    }).execute()
    
    # 2. Hibrit skor hesapla
    for tweet in candidates:
        similarity = tweet['similarity']  # 0-1 (cosine)
        engagement = normalize(tweet['engagement_score'])  # 0-1
        algo = tweet['algo_score'] / 100  # 0-1
        
        # AÄŸÄ±rlÄ±klÄ± skor
        tweet['hybrid_score'] = (
            similarity * 0.4 +      # Topic uyumu
            engagement * 0.35 +     # GerÃ§ek viral performans
            algo * 0.25             # Algoritma uyumluluk
        )
    
    # 3. Ã‡eÅŸitlilik filtresi (hep aynÄ± tip tweet seÃ§me)
    selected = diversity_select(candidates, limit=limit)
    # - En az 1 kÄ±sa tweet + 1 uzun tweet
    # - En az 1 soru + 1 statement
    # - FarklÄ± aÃ§Ä±lÄ±ÅŸ pattern'leri
    
    return selected
```

**Supabase RPC Function:**
```sql
CREATE OR REPLACE FUNCTION match_source_tweets(
    query_embedding vector(1536),
    source_id_param UUID,
    match_count INT DEFAULT 20
) RETURNS TABLE (
    id UUID,
    content TEXT,
    likes INT,
    retweets INT,
    engagement_score FLOAT,
    algo_score FLOAT,
    tweet_type TEXT,
    similarity FLOAT
) AS $$
BEGIN
    RETURN QUERY
    SELECT 
        st.id, st.content, st.likes, st.retweets,
        st.engagement_score, st.algo_score, st.tweet_type,
        1 - (st.embedding <=> query_embedding) AS similarity
    FROM source_tweets st
    WHERE st.source_id = source_id_param
        AND st.embedding IS NOT NULL
    ORDER BY st.embedding <=> query_embedding
    LIMIT match_count;
END;
$$ LANGUAGE plpgsql;
```

---

### Sprint 4: Constraint Engine (0.5 gÃ¼n)
**AmaÃ§:** Hard limit'ler ile garanti stil uyumu

**GÃ¶revler:**
- [ ] `services/style_constraints.py` oluÅŸtur

**Constraint Sistemi:**
```python
class StyleConstraints:
    """Stil profilinden Ã§Ä±karÄ±lan hard constraint'ler"""
    
    def __init__(self, fingerprint: dict, viral_patterns: dict):
        self.rules = self._build_rules(fingerprint, viral_patterns)
    
    def _build_rules(self, fp, vp) -> dict:
        rules = {}
        
        # 1. Uzunluk constrainti
        avg_len = fp.get('avg_length', 150)
        rules['min_length'] = int(avg_len * 0.5)
        rules['max_length'] = int(avg_len * 1.5)
        # Viral pattern'den optimal uzunluk
        rules['optimal_length'] = vp.get('viral_avg_length', avg_len)
        
        # 2. Emoji constrainti
        emoji = fp.get('emoji_strategy', {})
        if emoji.get('style') == 'no_emoji':
            rules['emoji_policy'] = 'BANNED'
            rules['emoji_whitelist'] = []
        elif emoji.get('style') == 'light':
            rules['emoji_policy'] = 'WHITELIST'
            rules['emoji_whitelist'] = emoji.get('top_emojis', [])[:5]
        else:
            rules['emoji_policy'] = 'ALLOWED'
            rules['emoji_whitelist'] = emoji.get('top_emojis', [])[:10]
        
        # 3. Hashtag constrainti
        ht = fp.get('hashtag_usage', 0)
        rules['hashtag_policy'] = 'BANNED' if ht < 0.05 else 'ALLOWED'
        
        # 4. Link constrainti (algoritma bilgisi ile)
        link = fp.get('link_usage', 0)
        rules['link_policy'] = 'BANNED'  # Her zaman ban (algoritma cezasÄ±)
        rules['link_in_reply'] = True     # Reply'a koy Ã¶nerisi
        
        # 5. Dil constrainti
        lang = fp.get('language_mix', {})
        rules['language_style'] = lang.get('language_style', 'mixed')
        rules['english_word_pct_target'] = lang.get('english_word_pct', 10)
        
        # 6. SatÄ±r yapÄ±sÄ±
        line = fp.get('line_structure', {})
        if line.get('multiline_pct', 0) > 50:
            rules['line_break_policy'] = 'REQUIRED'
            rules['target_lines'] = line.get('avg_lines_per_tweet', 3)
        elif line.get('multiline_pct', 0) < 15:
            rules['line_break_policy'] = 'BANNED'
        else:
            rules['line_break_policy'] = 'OPTIONAL'
        
        # 7. AÃ§Ä±lÄ±ÅŸ constrainti (viral pattern'den)
        opening = fp.get('opening_psychology', {})
        if opening:
            dominant = opening.get('dominant_pattern', 'direct')
            rules['preferred_opening'] = dominant
            rules['opening_distribution'] = opening.get('distribution', {})
        
        # 8. KapanÄ±ÅŸ constrainti
        closing = fp.get('closing_strategy', {})
        if closing:
            rules['preferred_closing'] = closing.get('dominant', 'statement')
        
        # 9. YasaklÄ± kalÄ±plar (kiÅŸinin ASLA yapmadÄ±ÄŸÄ±)
        rules['banned_patterns'] = self._detect_banned(fp)
        
        return rules
    
    def _detect_banned(self, fp) -> List[str]:
        """KiÅŸinin ASLA yapmadÄ±ÄŸÄ± ÅŸeyleri tespit et"""
        banned = []
        if fp.get('hashtag_usage', 0) < 0.02:
            banned.append("ASLA hashtag kullanma (#)")
        if fp.get('emoji_strategy', {}).get('style') == 'no_emoji':
            banned.append("ASLA emoji kullanma")
        if fp.get('link_usage', 0) < 0.05:
            banned.append("ASLA link paylaÅŸma")
        if fp.get('exclamation_ratio', 0) < 0.05:
            banned.append("ASLA Ã¼nlem iÅŸareti kullanma (!)")
        if fp.get('question_ratio', 0) < 0.03:
            banned.append("Soru sorma, statement yap")
        cap = fp.get('capitalization', {})
        if cap.get('uses_all_caps_emphasis_pct', 0) < 3:
            banned.append("BÃœYÃœK HARF ile vurgulama yapma")
        return banned
    
    def to_prompt(self) -> str:
        """Constraint'leri prompt formatÄ±na Ã§evir"""
        lines = ["## ZORUNLU KURALLAR (Ä°hlal Etme!)"]
        
        lines.append(f"- Karakter limiti: {self.rules['min_length']}-{self.rules['max_length']} karakter")
        
        if self.rules.get('emoji_policy') == 'BANNED':
            lines.append("- âŒ Emoji KULLANMA")
        elif self.rules.get('emoji_policy') == 'WHITELIST':
            emojis = ' '.join(self.rules['emoji_whitelist'])
            lines.append(f"- Sadece bu emojileri kullan: {emojis}")
        
        if self.rules.get('hashtag_policy') == 'BANNED':
            lines.append("- âŒ Hashtag KULLANMA")
        
        lines.append("- âŒ Link KOYMA (algoritma %50-90 ceza veriyor)")
        
        if self.rules.get('line_break_policy') == 'REQUIRED':
            lines.append(f"- SatÄ±r kÄ±rÄ±lmasÄ± KULLAN (~{self.rules.get('target_lines', 3)} satÄ±r)")
        elif self.rules.get('line_break_policy') == 'BANNED':
            lines.append("- Tek blok yaz, satÄ±r kÄ±rÄ±lmasÄ± YAPMA")
        
        for ban in self.rules.get('banned_patterns', []):
            lines.append(f"- {ban}")
        
        return '\n'.join(lines)
    
    def validate(self, generated_text: str) -> Tuple[bool, List[str]]:
        """Ãœretilen tweet'in constraint'lere uyumunu kontrol et"""
        violations = []
        
        # Uzunluk kontrolÃ¼
        if len(generated_text) < self.rules['min_length']:
            violations.append('too_short')
        if len(generated_text) > self.rules['max_length']:
            violations.append('too_long')
        
        # Emoji kontrolÃ¼
        if self.rules.get('emoji_policy') == 'BANNED' and has_emoji(generated_text):
            violations.append('has_emoji')
        
        # Hashtag kontrolÃ¼
        if self.rules.get('hashtag_policy') == 'BANNED' and '#' in generated_text:
            violations.append('has_hashtag')
        
        # Link kontrolÃ¼
        if 'http' in generated_text.lower():
            violations.append('has_link')
        
        return len(violations) == 0, violations
```

---

### Sprint 5: Multi-Shot Ranking Engine (0.5 gÃ¼n)
**AmaÃ§:** 5 variant Ã¼retip en iyisini seÃ§me

**GÃ¶revler:**
- [ ] `services/style_ranker.py` oluÅŸtur

**Ranking Sistemi:**
```python
class StyleRanker:
    """Ãœretilen variant'larÄ± stil + algoritma uyumuna gÃ¶re sÄ±rala"""
    
    def rank(
        self, 
        variants: List[str], 
        style_fingerprint: dict,
        constraints: StyleConstraints,
        reference_tweets: List[dict],
        topic: str
    ) -> List[Tuple[str, float, dict]]:
        """
        Returns: [(text, final_score, score_breakdown), ...]
        """
        scored = []
        
        for variant in variants:
            scores = {}
            
            # 1. Constraint uyumu (pass/fail + violation count)
            passed, violations = constraints.validate(variant)
            scores['constraint'] = 1.0 if passed else max(0, 1.0 - len(violations) * 0.3)
            
            # 2. Uzunluk uyumu (Gaussian, optimal uzunluÄŸa yakÄ±nlÄ±k)
            optimal = constraints.rules.get('optimal_length', 150)
            length_diff = abs(len(variant) - optimal) / optimal
            scores['length'] = max(0, 1.0 - length_diff)
            
            # 3. Noktalama uyumu (fingerprint ile karÅŸÄ±laÅŸtÄ±r)
            scores['punctuation'] = self._punctuation_similarity(variant, style_fingerprint)
            
            # 4. Kelime daÄŸÄ±lÄ±mÄ± benzerliÄŸi
            scores['vocabulary'] = self._vocabulary_similarity(variant, reference_tweets)
            
            # 5. Embedding benzerliÄŸi (ortalama referans tweet'lere)
            scores['embedding'] = self._embedding_similarity(variant, reference_tweets)
            
            # 6. Algoritma skoru
            scores['algorithm'] = self._algorithm_score(variant)
            
            # 7. Hook kalitesi (aÃ§Ä±lÄ±ÅŸ gÃ¼cÃ¼)
            scores['hook'] = self._hook_quality(variant)
            
            # 8. Reply tetikleme potansiyeli
            scores['reply_potential'] = self._reply_potential(variant)
            
            # AÄŸÄ±rlÄ±klÄ± final skor
            final = (
                scores['constraint'] * 0.20 +      # Kurallara uyum
                scores['length'] * 0.05 +           # Uzunluk uyumu
                scores['punctuation'] * 0.10 +      # Noktalama uyumu
                scores['vocabulary'] * 0.15 +       # Kelime benzerliÄŸi
                scores['embedding'] * 0.15 +        # Semantik benzerlik
                scores['algorithm'] * 0.15 +        # Algoritma uyumu
                scores['hook'] * 0.10 +             # Hook kalitesi
                scores['reply_potential'] * 0.10    # Reply potansiyeli
            )
            
            scored.append((variant, final, scores))
        
        # SÄ±rala ve dÃ¶ndÃ¼r
        scored.sort(key=lambda x: x[1], reverse=True)
        return scored
    
    def _algorithm_score(self, text: str) -> float:
        """X algoritma uyumluluk skoru"""
        score = 0.5
        
        # Link yok â†’ iyi
        if 'http' not in text.lower(): score += 0.15
        
        # Soru var â†’ reply tetikler (13.5x aÄŸÄ±rlÄ±k)
        if '?' in text: score += 0.1
        
        # Dwell time: 20-60 kelime optimal
        words = len(text.split())
        if 20 <= words <= 60: score += 0.1
        
        # Self-contained (link yok, bilgi direkt)
        if 'http' not in text and words > 10: score += 0.05
        
        # SatÄ±r kÄ±rÄ±lmasÄ± â†’ okunabilirlik â†’ dwell time
        if '\n' in text: score += 0.05
        
        # Report riski dÃ¼ÅŸÃ¼k (toxic deÄŸil)
        score += 0.05  # Default non-toxic varsayÄ±m
        
        return min(score, 1.0)
    
    def _hook_quality(self, text: str) -> float:
        """Ä°lk cÃ¼mlenin dikkat Ã§ekiciliÄŸi"""
        first_line = text.split('\n')[0].strip()
        score = 0.3  # Baseline
        
        # KÄ±sa ve punch'lÄ± aÃ§Ä±lÄ±ÅŸ
        if len(first_line.split()) <= 8: score += 0.2
        
        # Rakamla aÃ§Ä±lÄ±ÅŸ
        if first_line[0].isdigit(): score += 0.15
        
        # Soru ile aÃ§Ä±lÄ±ÅŸ
        if '?' in first_line: score += 0.15
        
        # GÃ¼Ã§lÃ¼ kelimeler
        power_words = ['asla', 'herkes', 'kimse', 'sÄ±r', 'gerÃ§ek', 'aslÄ±nda', 
                       'never', 'everyone', 'nobody', 'secret', 'truth', 'actually']
        if any(w in first_line.lower() for w in power_words): score += 0.15
        
        return min(score, 1.0)
```

---

### Sprint 6: Prompt Builder v2 + Entegrasyon (1 gÃ¼n)
**AmaÃ§:** TÃ¼m katmanlarÄ± birleÅŸtiren yeni prompt builder

**GÃ¶revler:**
- [ ] `prompts/style_prompt_v2.py` oluÅŸtur
- [ ] `build_final_prompt` fonksiyonunu gÃ¼ncelle
- [ ] server.py entegrasyonu

**Yeni Prompt YapÄ±sÄ±:**
```python
def build_style_enhanced_prompt(
    topic: str,
    style_fingerprint: dict,
    viral_patterns: dict,
    constraints: StyleConstraints,
    reference_tweets: List[dict],
    algorithm_knowledge: str,
    persona: str,
    tone: str,
    language: str,
) -> str:
    """TÃ¼m katmanlarÄ± birleÅŸtiren mega prompt"""
    
    sections = []
    
    # 1. Temel kimlik
    sections.append(SYSTEM_IDENTITY)  # Mevcut
    
    # 2. X Algoritma bilgisi (compact versiyon)
    sections.append(ALGORITHM_KNOWLEDGE_COMPACT)
    
    # 3. Stil DNA (AI analizi)
    sections.append(f"## STÄ°L DNA\n{style_fingerprint.get('ai_analysis', '')}")
    
    # 4. Mikro kurallar (somut veriler)
    micro = StyleAnalyzer().generate_style_prompt(style_fingerprint)
    sections.append(micro)
    
    # 5. Viral pattern insight
    sections.append(format_viral_patterns(viral_patterns))
    
    # 6. Hard constraint'ler
    sections.append(constraints.to_prompt())
    
    # 7. Referans Ã¶rnekler (RAG'den gelen 5-8 tweet)
    if reference_tweets:
        examples = "\n\n".join([
            f"Ã–rnek ({t['likes']}â¤): {t['content']}" 
            for t in reference_tweets[:8]
        ])
        sections.append(f"## REFERANS Ã–RNEKLER\nBu tarzda yaz, kopyalama:\n{examples}")
    
    # 8. Algoritma odaklÄ± CTA stratejisi
    sections.append("""## ALGORÄ°TMA TAKTÄ°ÄÄ°
- Reply tetikle (13.5x boost): Tweet sonunda dÃ¼ÅŸÃ¼ndÃ¼rÃ¼cÃ¼ element bÄ±rak
- Dwell time artÄ±r (10x boost): DeÄŸerli bilgi ver, scroll durdur  
- Link KOYMA (-%50-90 eriÅŸim)
- Dil tutarlÄ±lÄ±ÄŸÄ±nÄ± koru (karÄ±ÅŸÄ±k dil = 0.01x penalty)""")
    
    return '\n\n'.join(sections)
```

**server.py Entegrasyonu:**
```python
@api_router.post("/generate/tweet")
async def generate_tweet(request: TweetGenerateRequest, user=Depends(require_auth)):
    # ... mevcut kod ...
    
    if request.style_profile_id:
        # Style Lab v2 akÄ±ÅŸÄ±
        profile = get_profile(request.style_profile_id, user.id)
        fingerprint = profile['style_fingerprint']
        viral_patterns = profile.get('viral_patterns', {})
        
        # Constraint engine
        constraints = StyleConstraints(fingerprint, viral_patterns)
        
        # AkÄ±llÄ± RAG
        reference_tweets = await get_style_examples(
            topic=request.topic,
            source_id=profile['source_ids'][0],
            limit=8,
            strategy="hybrid"
        )
        
        # Style-enhanced prompt
        system_prompt = build_style_enhanced_prompt(
            topic=request.topic,
            style_fingerprint=fingerprint,
            viral_patterns=viral_patterns,
            constraints=constraints,
            reference_tweets=reference_tweets,
            algorithm_knowledge=ALGORITHM_KNOWLEDGE_COMPACT,
            persona=request.persona,
            tone=request.tone,
            language=request.language,
        )
        
        # Multi-shot: 5 variant Ã¼ret
        contents, tokens = await generate_with_model(
            system_prompt, "Ä°Ã§eriÄŸi Ã¼ret.", 
            variants=5,  # Her zaman 5 Ã¼ret
            user_id=user.id
        )
        
        # Ranking
        ranker = StyleRanker()
        ranked = ranker.rank(contents, fingerprint, constraints, reference_tweets, request.topic)
        
        # Top 3'Ã¼ dÃ¶ndÃ¼r (kullanÄ±cÄ± istediÄŸi kadar variant gÃ¶rsÃ¼n)
        best = ranked[:max(request.variants, 3)]
        
        # Constraint violation olan variant'larÄ± filtrele
        best = [v for v in best if v[2]['constraint'] >= 0.7]
        
        # Posting Ã¶nerisi ekle
        posting_suggestion = get_posting_suggestion(viral_patterns)
        
        return GenerationResponse(
            variants=[...],
            posting_suggestion=posting_suggestion,  # Yeni alan
            style_scores=[v[2] for v in best],      # Yeni alan
        )
```

---

### Sprint 7: Style Profile v2 KayÄ±t + UI (0.5 gÃ¼n)
**AmaÃ§:** Yeni analiz verilerini kaydetme + frontend gÃ¼ncelleme

**GÃ¶revler:**
- [ ] `style_profiles` tablosuna yeni alanlar:
```sql
ALTER TABLE style_profiles ADD COLUMN IF NOT EXISTS viral_patterns JSONB DEFAULT '{}';
ALTER TABLE style_profiles ADD COLUMN IF NOT EXISTS constraints JSONB DEFAULT '{}';
ALTER TABLE style_profiles ADD COLUMN IF NOT EXISTS algo_insights JSONB DEFAULT '{}';
ALTER TABLE style_profiles ADD COLUMN IF NOT EXISTS tweet_count INT DEFAULT 0;
ALTER TABLE style_profiles ADD COLUMN IF NOT EXISTS avg_engagement FLOAT;
ALTER TABLE style_profiles ADD COLUMN IF NOT EXISTS profile_version INT DEFAULT 2;
```

- [ ] Frontend: StyleLabPage.jsx gÃ¼ncellemeleri
  - Analiz baÅŸlatÄ±nca progress bar (tweet Ã§ekme â†’ analiz â†’ embedding â†’ skor)
  - Stil kartÄ±nda yeni bilgiler:
    - "Viral Pattern: Soru ile aÃ§Ä±lÄ±ÅŸ + kÄ±sa cÃ¼mleler" 
    - "Algoritma Skoru: 78/100"
    - "En gÃ¼Ã§lÃ¼ saatler: 09:00, 13:00, 21:00"
    - "YasaklÄ±: emoji, hashtag, link"
  - Generation sonucunda skor gÃ¶sterimi:
    - "Stil Uyumu: %87"
    - "Algoritma Skoru: 82/100"
    - "Posting Ã–nerisi: 13:00-14:00 arasÄ± paylaÅŸ"

---

### Sprint 8: Test & Ä°terasyon (0.5 gÃ¼n)
**AmaÃ§:** GerÃ§ek kullanÄ±cÄ± verileri ile test

**GÃ¶revler:**
- [ ] Semih KÄ±ÅŸlar (@semihdev) profili ile v1 vs v2 karÅŸÄ±laÅŸtÄ±rma
- [ ] 3 farklÄ± hesap ile test:
  - TR teknik hesap (Ã¶r: @semihdev)
  - TR mizah hesabÄ±
  - EN tech hesabÄ±
- [ ] Blind test: v1 vs v2 Ã§Ä±ktÄ±larÄ±nÄ± yan yana karÅŸÄ±laÅŸtÄ±r
- [ ] Skor kalibrasyonu: ranking aÄŸÄ±rlÄ±klarÄ±nÄ± ayarla
- [ ] Edge case'ler: Ã§ok az tweet'li hesap, Ã§ok niÅŸ hesap

---

## Toplam Tahmini SÃ¼re: 5-6 gÃ¼n

| Sprint | Konu | SÃ¼re |
|--------|------|------|
| 0 | Veri Toplama (500+ tweet) | 0.5 gÃ¼n |
| 1 | Algoritma Skoru | 0.5 gÃ¼n |
| 2 | Mikro-Dilbilim v2 | 1 gÃ¼n |
| 3 | Embedding & RAG v2 | 1 gÃ¼n |
| 4 | Constraint Engine | 0.5 gÃ¼n |
| 5 | Multi-Shot Ranking | 0.5 gÃ¼n |
| 6 | Prompt Builder v2 + Entegrasyon | 1 gÃ¼n |
| 7 | DB + UI | 0.5 gÃ¼n |
| 8 | Test | 0.5 gÃ¼n |

## Ek Maliyet
- Apify tweet Ã§ekme: ~$0.28 / kullanÄ±cÄ± profil
- Embedding: ~$0.01 / 500 tweet (text-embedding-3-small)
- Ekstra variant Ã¼retim: 5x yerine 1x â†’ Maverick inference maliyeti ~5x ama Ã§ok ucuz ($0.85/1M)
- **Toplam ek maliyet per kullanÄ±cÄ±: ~$0.35**

## Profil GÃ¼ncelleme Stratejisi
KullanÄ±cÄ± aylar sonra tekrar analiz istediÄŸinde:
- Eski tweet'ler + yeni tweet'ler **merge** edilir (deduplicate)
- Yeni analiz Ã§alÄ±ÅŸÄ±r, style_fingerprint gÃ¼ncellenir
- Eski embedding'ler kalÄ±r, yeni tweet'lere embedding eklenir
- `profile_version` artÄ±rÄ±lÄ±r, `updated_at` gÃ¼ncellenir
- Constraint'ler yeniden hesaplanÄ±r (stil deÄŸiÅŸmiÅŸ olabilir)

## Progressive Analiz (UX)
KullanÄ±cÄ±yÄ± bekletmemek iÃ§in 2 aÅŸamalÄ±:
1. **HÄ±zlÄ± analiz (15-30sn):** Ä°lk 50 tweet Ã§ek â†’ temel mikro-dilbilim + AI DNA â†’ profil v2-lite kaydedilir, hemen kullanÄ±labilir
2. **Derin analiz (arka plan, 2-3dk):** 500+ tweet Ã§ek â†’ embedding â†’ algo skoru â†’ viral pattern â†’ profil v2-full'e gÃ¼ncelle
- UI'da "Profilin hazÄ±rlanÄ±yor... %40" progress bar
- Derin analiz bitince bildirim: "Stil profilin gÃ¼Ã§lendirildi!"

## BaÄŸÄ±mlÄ±lÄ±klar
- [x] Maverick fine-tune tamamlanmasÄ± (ÅŸu an Ã§alÄ±ÅŸÄ±yor)
- [ ] Supabase pgvector extension (muhtemelen zaten aktif)
- [ ] OpenAI embedding API key (mevcut)
- [ ] Tweet veri kaynaÄŸÄ±: Apify vs X API karÅŸÄ±laÅŸtÄ±rmasÄ± yapÄ±lacak
